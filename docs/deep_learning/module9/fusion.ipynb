{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion Conv-BN et RepVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r1pY7xYhCLKe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAvgPool2D, Flatten, ReLU, Softmax, Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Add\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = 32, 32, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des poids des Conv $3 \\times 3$ et des BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons comment s'articulent les poids dans les couches de convolutions et de batchnormalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zA17F4n2CRmb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "testing_conv_init (Conv2D)   (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "testing_bn_init (BatchNormal (None, 32, 32, 16)        64        \n",
      "=================================================================\n",
      "Total params: 512\n",
      "Trainable params: 480\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=True, kernel_initializer='he_uniform', name='testing_conv_init')(input)\n",
    "x= BatchNormalization(name=f'testing_bn_init')(x)\n",
    "model = Model(input, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude de la couche convolutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.09736294,  0.01110744,  0.38817808,  0.02365676,\n",
       "            0.37265095,  0.22067323,  0.44893858, -0.4457162 ,\n",
       "            0.2723634 ,  0.21101996, -0.42767352,  0.39105812,\n",
       "           -0.38641602, -0.39619464, -0.12856498,  0.00230291],\n",
       "          [-0.15622476,  0.08576027, -0.39533868,  0.14336786,\n",
       "            0.09569708,  0.05594608,  0.05045763, -0.15595007,\n",
       "           -0.05612397, -0.19001147,  0.2724487 ,  0.3459774 ,\n",
       "            0.01586419,  0.08192965,  0.32559904,  0.04557905],\n",
       "          [-0.37503266,  0.05977681, -0.05365878,  0.34279034,\n",
       "           -0.22699383, -0.20862746,  0.13931164, -0.20776296,\n",
       "            0.12117836,  0.06501201, -0.28448707,  0.2668244 ,\n",
       "            0.2704514 , -0.34608564, -0.35193035, -0.3525829 ]],\n",
       " \n",
       "         [[ 0.11737838,  0.14824674, -0.00563487,  0.3061553 ,\n",
       "            0.01097953,  0.23561516, -0.4535907 , -0.4175086 ,\n",
       "            0.4607807 , -0.37212858, -0.30806714,  0.14160755,\n",
       "            0.24837866,  0.12601265,  0.2622976 ,  0.3263745 ],\n",
       "          [-0.34101892,  0.31189194, -0.11391068,  0.14759234,\n",
       "           -0.30657652, -0.13771534,  0.45230624,  0.22417751,\n",
       "            0.0407432 ,  0.07712099, -0.2991236 , -0.1449846 ,\n",
       "           -0.00576615,  0.26184592, -0.2169587 , -0.2828556 ],\n",
       "          [-0.20167324, -0.1357314 , -0.29285318,  0.33294716,\n",
       "            0.23413381, -0.00896761, -0.31519616,  0.14762929,\n",
       "           -0.18309683, -0.32602823,  0.10732868, -0.15018934,\n",
       "           -0.27001262,  0.0079852 , -0.20946455, -0.10388163]],\n",
       " \n",
       "         [[ 0.2783232 ,  0.05878171, -0.35913152,  0.40182415,\n",
       "            0.092141  , -0.13399044,  0.03964153,  0.06443217,\n",
       "            0.46447167, -0.41376618,  0.10037312,  0.42862818,\n",
       "            0.17965165, -0.13864604,  0.04373595, -0.13044247],\n",
       "          [-0.45564812, -0.33004287,  0.3405182 ,  0.39920047,\n",
       "           -0.25907567,  0.15346971, -0.02812734, -0.19346526,\n",
       "           -0.12104025, -0.4278583 ,  0.23774037,  0.3617756 ,\n",
       "           -0.0419741 ,  0.09765604, -0.26489764, -0.43987206],\n",
       "          [ 0.07685599,  0.04646841, -0.06539023,  0.02657837,\n",
       "            0.44154963,  0.21664849,  0.4601402 ,  0.21062568,\n",
       "            0.34529766,  0.30855897,  0.40019926, -0.26326853,\n",
       "           -0.04224968, -0.46108606, -0.37318596, -0.42175823]]],\n",
       " \n",
       " \n",
       "        [[[-0.3455502 ,  0.46076384, -0.15374777,  0.29009756,\n",
       "           -0.1667389 ,  0.31607136,  0.26514402,  0.3037739 ,\n",
       "           -0.0812335 ,  0.23732015,  0.07654181, -0.0679315 ,\n",
       "           -0.31959674, -0.28597334, -0.10885993,  0.408551  ],\n",
       "          [ 0.14297041, -0.09827566,  0.40382537, -0.4178524 ,\n",
       "           -0.01861295, -0.35064167,  0.45108077, -0.12225789,\n",
       "           -0.29017037,  0.23471412,  0.14587566, -0.36702543,\n",
       "           -0.3979674 ,  0.29743996, -0.39642572, -0.0245271 ],\n",
       "          [-0.0504581 ,  0.46684763,  0.37567046,  0.20170256,\n",
       "           -0.36068565, -0.17110959,  0.30896595,  0.09373525,\n",
       "           -0.21380827, -0.395913  ,  0.24522027,  0.36945108,\n",
       "           -0.06558827, -0.4528262 ,  0.08612862,  0.3769413 ]],\n",
       " \n",
       "         [[-0.06688267,  0.11741361, -0.14751217, -0.01143798,\n",
       "            0.30352488,  0.23946908,  0.15358987, -0.11050937,\n",
       "           -0.05894232, -0.22810066,  0.3403059 ,  0.23961261,\n",
       "           -0.16434652,  0.11093548,  0.00398877, -0.11645409],\n",
       "          [-0.37574512,  0.3296124 , -0.05067682, -0.09595928,\n",
       "           -0.2214837 ,  0.35080925, -0.02972579,  0.1532239 ,\n",
       "            0.18751535, -0.02314931, -0.18395177, -0.03616032,\n",
       "            0.27149966, -0.4180094 ,  0.28113106,  0.4416559 ],\n",
       "          [-0.2833048 ,  0.03007612,  0.34248617, -0.24044934,\n",
       "            0.16455218,  0.15701613,  0.20851544, -0.25038487,\n",
       "           -0.21328565, -0.23982422,  0.37252668,  0.15518335,\n",
       "            0.28911796,  0.44327244,  0.14157644,  0.26580074]],\n",
       " \n",
       "         [[ 0.28428563, -0.18229985, -0.20275667,  0.1955097 ,\n",
       "           -0.3543805 , -0.14616191,  0.28929475,  0.14749238,\n",
       "            0.2464734 , -0.46400836, -0.02009585,  0.3317866 ,\n",
       "           -0.20362425, -0.42040807, -0.17440939, -0.01986095],\n",
       "          [ 0.44240263,  0.1606206 , -0.4160647 ,  0.27185783,\n",
       "            0.06790957, -0.32414603, -0.23126818, -0.29003426,\n",
       "            0.12488225,  0.16395304, -0.3259102 , -0.38798535,\n",
       "           -0.43922648, -0.3790248 ,  0.12847778,  0.13634267],\n",
       "          [-0.02119684,  0.28930375, -0.4681574 ,  0.28300878,\n",
       "            0.40201846,  0.1442084 ,  0.19728747, -0.02722415,\n",
       "            0.42741737, -0.21063939,  0.42403385,  0.3592575 ,\n",
       "           -0.20373034, -0.4468028 , -0.08656737, -0.20087367]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02782702,  0.01967528,  0.07292607,  0.389165  ,\n",
       "            0.36987802,  0.18188533,  0.04504755,  0.41210625,\n",
       "            0.01592982, -0.11140019, -0.11948159,  0.10680953,\n",
       "           -0.11324027,  0.39144352, -0.35009858,  0.26030532],\n",
       "          [ 0.09090939, -0.09534436,  0.03001484, -0.1512312 ,\n",
       "           -0.3052565 ,  0.3308485 , -0.24254534, -0.10194659,\n",
       "            0.00120181,  0.38111654,  0.21856287,  0.32130632,\n",
       "           -0.33506405,  0.44324157,  0.32223514, -0.2681678 ],\n",
       "          [ 0.4114515 , -0.40250486,  0.3429939 , -0.2685476 ,\n",
       "            0.37336466,  0.18623039, -0.23775014,  0.18628749,\n",
       "           -0.07814869,  0.15818772, -0.21979165, -0.44143543,\n",
       "           -0.09982735, -0.17906868, -0.11419335, -0.10601136]],\n",
       " \n",
       "         [[-0.04968157,  0.33098873, -0.35580167,  0.19270661,\n",
       "            0.33699194,  0.41285995,  0.23392567,  0.4191365 ,\n",
       "           -0.04616675,  0.22136435, -0.29591143,  0.20710972,\n",
       "           -0.3502412 , -0.10524371, -0.32441103,  0.35304728],\n",
       "          [-0.45383817, -0.21678528,  0.13484439, -0.23379093,\n",
       "           -0.038737  ,  0.02832112, -0.36996582, -0.19088644,\n",
       "            0.32281145,  0.14254984,  0.24848273,  0.3904991 ,\n",
       "           -0.41010976, -0.4470079 , -0.13003865, -0.41824162],\n",
       "          [ 0.14215276,  0.29101995, -0.40439036, -0.43802816,\n",
       "            0.33089224, -0.34787324,  0.32901898, -0.11648187,\n",
       "           -0.07495171,  0.4408585 ,  0.24113259, -0.08504415,\n",
       "            0.0623028 ,  0.23243883, -0.19044554,  0.3553057 ]],\n",
       " \n",
       "         [[-0.09105429,  0.30605808,  0.41014054,  0.33675548,\n",
       "           -0.05541334,  0.1684458 , -0.12973395, -0.1533834 ,\n",
       "           -0.00280687, -0.07284549,  0.35922107,  0.09879085,\n",
       "            0.43200687,  0.02035648,  0.36917636, -0.4091605 ],\n",
       "          [-0.22962008,  0.13721845, -0.12232229, -0.2520702 ,\n",
       "            0.07350466,  0.042968  ,  0.31936017,  0.36257067,\n",
       "           -0.10858962, -0.18460804, -0.1590521 , -0.47047156,\n",
       "           -0.1503287 , -0.04001006, -0.11763006, -0.24719194],\n",
       "          [-0.32062727,  0.13543853,  0.0306963 , -0.16442779,\n",
       "           -0.37330386,  0.13838956,  0.03568128, -0.2321063 ,\n",
       "            0.07501194, -0.426333  ,  0.00162551,  0.04697415,\n",
       "           -0.20748636, -0.30767232,  0.43708238, -0.16146705]]]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv = model.get_layer(\"testing_conv_init\").get_weights()\n",
    "weights_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids forment une liste de deux élements : les poids des noyaux de convolutions et les biais. La méthode d'initalisation utilisée ici est `he_uniform`, développée dans l'article [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids dans une couche convolutive sont une liste de deux éléments : \n",
    "- `weights[0]` correspond aux poids des noyaux de convolution,\n",
    "- `weights[1]` correspond aux biais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights_conv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQ5L4FtrD6ei",
    "outputId": "8b874cef-55bd-43e3-cbe7-947ab9ef8cd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[0].shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les axes du tenseur de poids suivent les dimensions suivantes :\n",
    "\n",
    "- kernel_size1 : hauteur du kernel,\n",
    "- kernel_size2 : largeur du kernel,\n",
    "- channels_in : nombre des feature maps en entrée, \n",
    "- channels_out : nombres de features maps (filters) en sortie.\n",
    "\n",
    "`channels_out` est définie dans la couche convolutive via le paramètres `filters`, alors que la valeur `channels_in` est elle directement déterminée par le tenseur en entrée. C'est une différence de TensorFlow par rapport à Pytorch où `channels_in` et `channels_out` sont tous les deux des paramètres des couches convolutives.\n",
    "\n",
    "Ainsi, si l'on veut voir les poids du noyau de convolution par rapport au canal $0$ en la feature map de sortie $5$, on les obtient en regardant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22067323,  0.23561516, -0.13399044],\n",
       "       [ 0.31607136,  0.23946908, -0.14616191],\n",
       "       [ 0.18188533,  0.41285995,  0.1684458 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[0][:,:,0,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par défaut, les biais des couches de convolutions sont tous initialisés à zéro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude de la batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_bn = model.get_layer('testing_bn_init').get_weights()\n",
    "weights_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans une couche de Batchnormalization, on a 4 types de poids.\n",
    "\n",
    "- Les deux paramètres de scaling $\\gamma$ et de biais $\\beta$.\n",
    "- Les deux paramètres correspondant à la moyenne $\\mu$ et la variance $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous ces paramètres ne sont pas entraînables, comme on peut le voir dans la liste suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(var.name, var.trainable) for var in model.get_layer('testing_bn_init').variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 4, 16], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend.shape(model.get_layer('testing_bn_init').get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les $4$ paramètres sont tous des vecteurs de dimension $16$, ce qui correspond au nombre de feature maps en sortie de la couche convolutive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion d'une Convolution et d'une batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fusion d'une couche de convolution avec une couche de batchnorm ressort les poids et biais d'une nouvelle couche de convolution avec les noyaux de convolutions de même dimension.\n",
    "\n",
    "Etant donné le tenseur $W$ de poids des noyaux de convolution d'une couche convolutive et le tenseur de $4$ paramètres $B=(\\gamma, \\beta, \\mu, \\sigma)$ d'une couche de batchnormalization, on obtient les nouveaux poids et poids de la nouvelle couche convolutive via les formules suivantes.\n",
    "\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{\\gamma_{j} \\cdot W_{:,:,:,j}}{\\sqrt{\\sigma_{j} + \\epsilon}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "b_{j} = \\beta_{j} - \\frac{\\mu_{j}\\cdot\\gamma_{j}}{\\sqrt{\\sigma_{j} + \\epsilon}} \n",
    "$$\n",
    "\n",
    "On remarque ici que le biais de la nouvelle couche de convolution ne dépend que des paramètres de la couche de batchnorm. **Ce qui est cohérent avec la pratique de ne jamais mettre de biais dans une couche de convolution lorsqu'elle est suivie par une couche de batchnorm**.\n",
    "\n",
    "\n",
    "**Remarque** : le $\\epsilon$ présent ici est pour s'assurer que l'on ne divise jamais pas zéro, dans la pratique il est fixé à $0,001$.\n",
    "\n",
    "Ce qui nous donne, dans la pratique la fonction suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bHoHvowwHAor",
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "# https://scortex.io/batch-norm-folding-an-easy-way-to-improve-your-network-speed/\n",
    "# https://github.com/DingXiaoH/RepVGG/blob/4da799e33c890c624bfb484b2c35abafd327ba40/repvgg.py#L68\n",
    "\n",
    "def fuse_bn_conv(weights_conv, weights_bn, eps=0.001):\n",
    "    gamma = np.reshape(weights_bn[0], (1,1,1,weights_bn[0].shape[0]))\n",
    "    beta = weights_bn[1]\n",
    "    mean = weights_bn[2]\n",
    "    variance = np.reshape(weights_bn[3], (1,1,1,weights_bn[3].shape[0]))\n",
    "\n",
    "    new_weights = (weights_conv[0]*gamma) / np.sqrt(variance + eps)\n",
    "    new_bias = beta - mean*gamma/np.sqrt(variance+eps)\n",
    "\n",
    "    new_bias = np.reshape(new_bias, weights_bn[3].shape[0])\n",
    "\n",
    "    return new_weights, new_bias\n",
    "\n",
    "# In the code above, the reshaping is necessary to prevent a mistake if the dimension of the output O was the same as the dimension of the input I. \n",
    "\n",
    "# def get_equivalent_kernel_bias(self):\n",
    "#    kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
    "#    kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
    "#    kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
    "#    return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Détaillons la fonction ci dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouveau tenseur de poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discutons premièrement de la formulation du nouveau tenseur de poids, et voyons pourquoi on modifie la forme de vecteurs $\\gamma$ et $\\sigma$.\n",
    "\n",
    "$W_{:,:,:,j}$ correspond dans la formule au noyau de convolution complet de la $j$-ième feature map de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv = model.get_layer(\"testing_conv_init\").get_weights()\n",
    "weights_conv[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a $16$ noyaux de convolution, chacun de dimensions $(3,3,3)$. Par exemple, pour $j=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[0][:,:,:,1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les vecteur $\\gamma$ et $\\sigma$ étant des vecteurs de dimension $16$, on va les \"transformer en tenseur\" de dimensions $(1,1,1,16)$ pour bien faire correspondre le produit suivant chaque axe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = np.reshape(weights_bn[3], (1,1,1,weights_bn[3].shape[0]))\n",
    "variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = np.reshape(weights_bn[0], (1,1,1,weights_bn[0].shape[0]))\n",
    "gamma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screen](images/fuse_conv_bn.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au final, la formule\n",
    "\n",
    "```python\n",
    "new_weights = (weights_conv[0]*gamma) / np.sqrt(variance + eps)\n",
    "```\n",
    "\n",
    "résume tout cela, tous les tenseurs ayant le nombre d'axes, les opérations sont vectorisées et se font axe par axe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouveau tenseur de biais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlACrpn5JS_1",
    "outputId": "ce7f2944-5f0a-43bb-ca92-af9dd100b362"
   },
   "source": [
    "Le opérations de `reshape` n'ont pas ajouter de nouveaux scalaires, juste des axes, le calcul du biais se fait alors élément par élément pour tout $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification via les développements limités"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons un tenseur de poids $W$ repéresentatif du noyau d'une convolution et un tenseur de poids $B=(\\gamma, \\beta, \\mu, \\sigma)$ représentatif des coefficients d'une batchnormalization.\n",
    "\n",
    "Pour vérifier si tout marche bien, fixons volontairement le tenseur poids comme un tenseur de dimensions $(3,3,4,5)$, la dimension du noyau est toujours fixé à $(3,3)$ dans RepVGG, seules les dimensions `channels_in` et `channels_out` peuvent changer.\n",
    "\n",
    "Tous les coefficients du tenseur de poids seront fixés à $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 4, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_weights = np.ones(3*3*4*5).reshape((3,3,4,5))\n",
    "conv_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimension `channels_out` ayant été fixée à $5$, les vecteurs de la batchnormalization seront tous des vecteurs de dimension $5$. Fixons les coefficients suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def batchnorm_variables(gamma_coef: float, beta_coef: float, mu_coef: float, sigma_coef: float, channels: int):\n",
    "    gamma = gamma_coef*np.ones(channels)\n",
    "    beta = beta_coef*np.ones(channels)\n",
    "    mu = mu_coef*np.ones(channels)\n",
    "    sigma = sigma_coef*np.ones(channels)\n",
    "    \n",
    "    return [gamma, beta, mu, sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv, bn = fuse_bn_conv([conv_weights], batchnorm_variables(1,2,1,4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par définition, le nouveau tenseur de poids $\\widehat{W}$ de la convolution résultant de la fusion de l'ancienne convolution et de la batchnorm est donné par formule suivante.\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{\\gamma_{j} \\cdot W_{:,:,:,j}}{\\sqrt{\\sigma_{j} + \\epsilon}}\n",
    "$$\n",
    "\n",
    "De façon générale, pour $\\gamma_{j}, \\sigma_{j}$, on a le développement limité suivant.\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{\\gamma_{j} \\cdot W_{:,:,:,j}}{\\sqrt{\\sigma_{j} + \\epsilon}} = \\frac{\\gamma_{j}}{\\sqrt{\\sigma_{j}}}\\left[1- \\frac{1}{2\\sigma_{j}}\\epsilon + o(\\epsilon^{2})\\right]W_{:,:,:,j} \n",
    "$$\n",
    "\n",
    "Dans notre cas, $\\forall j, \\gamma_{j} = 1, \\sigma_{j} = 4$ d'où\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{W_{:,:,:,j}}{\\sqrt{4 + \\epsilon}} = \\left[\\frac{1}{2}- \\frac{1}{16}\\epsilon + o(\\epsilon^{2})\\right]W_{:,:,:,j} \\simeq \\left[\\frac{1}{2}- \\frac{1}{16}\\epsilon\\right]W_{:,:,:,j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_scaling_weight_factor(gamma, sigma):\n",
    "    return gamma/np.sqrt(sigma)*(1-0.001/(2*sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = compute_scaling_weight_factor(1,4)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751]],\n",
       "\n",
       "       [[0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751]],\n",
       "\n",
       "       [[0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv[:,:,:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui correspond bien à l'approximation obtenue par développement limité. On peut par exemple vérifier si $\\widehat{W}$ est approximativement égal à `conv` à $10^{-3}$ avec la commande `np.isclose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375]],\n",
       "\n",
       "       [[0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375]],\n",
       "\n",
       "       [[0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_weights_real = scale*np.ones(3*3*4*5).reshape((3,3,4,5))\n",
    "conv_weights_real[:,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si `np.mean(...)` $< 1$ alors le calcul est faux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.isclose(conv, conv_weights_real, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le biais, on a la formule suivante.\n",
    "\n",
    "$$\n",
    "b_{j} = \\beta_{j} - \\frac{\\mu_{j}\\cdot\\gamma_{j}}{\\sqrt{\\sigma_{j} + \\epsilon}} = \\beta_{j} - \\frac{\\mu_{j}\\cdot\\gamma_{j}}{\\sqrt{\\sigma_{j}}}\\left[1- \\frac{1}{2\\sigma_{j}}\\epsilon + o(\\epsilon^{2})\\right]\n",
    "$$\n",
    "\n",
    "dans notre cas, on a :\n",
    "\n",
    "- $\\beta_{j} = 2$,\n",
    "- $\\gamma_{j} = 1$,\n",
    "- $\\mu_{j} = 1$,\n",
    "- $\\sigma_{j} = 4$.\n",
    "\n",
    "$$\n",
    "b_{j} = 2 - \\frac{1}{2}\\left[1- \\frac{1}{8}\\epsilon + o(\\epsilon^{2})\\right] \\simeq 2 - \\frac{1}{2} - \\frac{1}{16}\\epsilon\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_scaling_bias_factor(gamma, beta, mu, sigma):\n",
    "    a = (mu*gamma)/np.sqrt(sigma)\n",
    "    b = 1 - 0.001/(2*sigma)\n",
    "    \n",
    "    return beta-a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_scale = compute_scaling_bias_factor(1,2,1,4)\n",
    "bias_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.50006249, 1.50006249, 1.50006249, 1.50006249, 1.50006249])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_real = bias_scale*np.ones(5)\n",
    "np.mean(np.isclose(bn_real, bn, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RepVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screen](./images/repvgg.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screen](./images/repvgg2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les couches convolutives dans RepVGG n'ayant que des noyaux $3\\times3$ ou $1\\times1$, on ne se préoccupe que de cela dans la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion d'une Conv $3\\times3$ avec une batchnorm puis transfert de poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons un modèle simple : une couche convolutive suivi d'une couche de batchnormalisation, pour simplifier on ne condière aucune couche d'activation (qui de toute façon ne rentre pas en jeu). Nous allons :\n",
    "\n",
    "1. Fusionner les deux couches pour créer un nouveau tenseur (poids, biais)\n",
    "2. Transférer ce nouveau tensor dans un modèle plus simple `model_after_fusion`.\n",
    "\n",
    "**Remarque** : la convolution dans `model_after_fusion` utilise elle bien un biais (`use_bias = True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38zgF1wjL5Sh",
    "outputId": "a3a18824-f730-4945-947c-714b80134cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        432       \n",
      "_________________________________________________________________\n",
      "bn (BatchNormalization)      (None, 32, 32, 16)        64        \n",
      "=================================================================\n",
      "Total params: 496\n",
      "Trainable params: 464\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=False, kernel_initializer='he_uniform', name='conv')(input)\n",
    "x= BatchNormalization(name='bn')(x)\n",
    "model_before_fusion = Model(input, x)\n",
    "model_before_fusion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        448       \n",
      "=================================================================\n",
      "Total params: 448\n",
      "Trainable params: 448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=True, kernel_initializer='he_normal', name='conv')(input)\n",
    "model_after_fusion = Model(input, x)\n",
    "model_after_fusion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = model_before_fusion.get_layer('conv').get_weights()[0]\n",
    "weights_2 = model_after_fusion.get_layer('conv').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023266133"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(weights_1-weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "eiD6G5F3JQiM"
   },
   "outputs": [],
   "source": [
    "conv = model_before_fusion.get_layer(\"conv\")\n",
    "bn = model_before_fusion.get_layer(\"bn\")\n",
    "  \n",
    "conv_weights, conv_biases = fuse_bn_conv(conv.get_weights(), bn.get_weights())\n",
    "model_after_fusion.get_layer(f\"conv\").set_weights([conv_weights, conv_biases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions que la mise en place des nouveaux poids s'est bien passée, ie que l'opération `set_weights()` n'a rien ajouté de supplémtentaire. Si tout se passe bien, `np.mean` ne devrait renvoyer que des `1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "6sGrv1qXK0Gu"
   },
   "outputs": [],
   "source": [
    "w0, b0 = fuse_bn_conv(model_before_fusion.get_layer(\"conv\").get_weights(), model_before_fusion.get_layer(\"bn\").get_weights())\n",
    "\n",
    "w1, b1 = model_after_fusion.get_layer(\"conv\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "An_AdwOtLtXm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(w0 == w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOcnujGYOvPa",
    "outputId": "93777f28-2bc4-4d11-bde8-73f7e3113a61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(b0 == b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc tout s'est bien passé. Reste maintenant à généraliser cette transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'idée de RepVGG est d'utiliser une architecture à la ResNet pour l'entraînement, avec des skips connections, puis lors du déploiement du modèle de reparamétrer les skips connections via des fusions Conv-BN afin de plus avoir qu'une architecture linéaire à la VGG, beaucoup plus rapide en inférence qu'une architecture à la ResNet.\n",
    "\n",
    "En plus de fusionner des $\\mathrm{Conv} 3 \\times 3$ avec des $\\mathrm{BN}$, il est aussi nécessaire de savoir faire les opérations suivantes.\n",
    "\n",
    "1. Convertir une $\\mathrm{Conv} 1 \\times 1$ en $\\mathrm{Conv} 3 \\times 3$ puis la fusionner avec la $\\mathrm{BN}$ correspondante.\n",
    "2. Convertir une $\\mathrm{id}$ en $\\mathrm{Conv} 3 \\times 3$ puis la fusionner avec la $\\mathrm{BN}$ correspondante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion d'une Conv $1 \\times 1$ en $3 \\times 3$ puis fusion avec la batchnorm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour convertir une conv 1x1 en conv 3x3 les nombres de canaux en entrée et en sortie importe peu, ce qu'il faut c'est modifier la dimension des noyaux de convolutions pour passer d'une dimension 1x1 à 3x3, et pour cela on utilise un padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        48        \n",
      "_________________________________________________________________\n",
      "bn (BatchNormalization)      (None, 32, 32, 16)        64        \n",
      "=================================================================\n",
      "Total params: 112\n",
      "Trainable params: 80\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=1, padding='same', use_bias=False, kernel_initializer='he_uniform', name='conv')(input)\n",
    "x= BatchNormalization(name='bn')(x)\n",
    "model_before_fusion_conv1 = Model(input, x)\n",
    "model_before_fusion_conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        448       \n",
      "=================================================================\n",
      "Total params: 448\n",
      "Trainable params: 448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=True, kernel_initializer='he_normal', name='conv')(input)\n",
    "model_after_fusion_conv1 = Model(input, x)\n",
    "model_after_fusion_conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_conv1 = model_before_fusion_conv1.get_layer('conv')\n",
    "weights_bn1 = model_before_fusion_conv1.get_layer('bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv1.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première chose à faire, c'est de transformer les noyaux de convolution $1\\times1$ en des noyaux de convolution $3\\times3$. Pour faire cela, on utilise la notion de \"padding\", déjà utilisée dans le cas des convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.227452]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv1.get_weights()[0][:,:,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a deux fonctions possibles pour faire ça. On peut utiliser soit la fonction de tensorflow.\n",
    "\n",
    "```python\n",
    "padded_conv1 = tf.pad(weights_conv1.get_weights()[0], [[1,1], [1, 1], [0,0], [0,0]], \"CONSTANT\")\n",
    "```\n",
    "\n",
    "Soit la fonction de numpy.\n",
    "\n",
    "```python\n",
    "padded_conv1 = np.pad(weights_conv1.get_weights()[0], pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)\n",
    "```\n",
    "\n",
    "Dans les deux cas, on a un paramètre donnant la taille du padding : `[[1,1], [1, 1], [0,0], [0,0]]`, c'est une liste de longueur le nombre d'axes du tenseur que l'on souhaite modifier, chaque élément de la liste nous dit de combien on doit agrandir au début et à la fin.\n",
    "\n",
    "`[[1,1], [1, 1], [0,0], [0,0]] = [[pad_avant_axe1, pad_arrière_axe1], [pad_avant_axe2, pad_arrière_axe2], [pad_avant_axe3, pad_arrière_axe3], [pad_avant_axe4, pad_arrière_axe4]]`\n",
    "\n",
    "Le dernier paramètre nous dit quoi rajouter aux endroits où l'on a agrandi, ici des constantes : la valeur $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "YPdg0ab5ajO5"
   },
   "outputs": [],
   "source": [
    "padded_conv1_tf = tf.pad(weights_conv1.get_weights()[0], [[1,1], [1, 1], [0,0], [0,0]], \"CONSTANT\")\n",
    "padded_conv1_np = np.pad(weights_conv1.get_weights()[0], pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux fonctions donnent le même résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(padded_conv1_tf.numpy()==padded_conv1_np)==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la fonction `set_weights()` demande d'utiliser des `np.array`, on va utiliser la fonction de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def pad_size_one_kernel(conv_weights):    \n",
    "    return np.pad(conv_weights[0], pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_weights_conv1 = pad_size_one_kernel(weights_conv1.get_weights())\n",
    "padded_weights_conv1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a transformé tous les noyaux de convolutions $1\\times1$ en noyaux $3\\times3$, chacun des `padded_weights_conv1[:,:,i,j]` pour $0 \\leq i \\leq 2$ et $0 \\leq j \\leq 15$ doit être une matrice $3\\times3$ où tous les éléments sont nuls sauf possiblement celui du milieu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def test_padded_kernel_conv(padded_kernel):\n",
    "    for i in range(3):\n",
    "        for j in range(16):\n",
    "            print(f'Matrix of size 3x3 : {padded_kernel[:,:,i,j].shape == (3,3)}')\n",
    "            squared_sum = 0\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    if k != 1 and l != 1:\n",
    "                        squared_sum += padded_kernel[:,:,i,j][k,l]**2\n",
    "            print(f'Squared sum is : {squared_sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n"
     ]
    }
   ],
   "source": [
    "test_padded_kernel_conv(padded_weights_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_conv = np.ones(1*1*3*16).reshape((1,1,3,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n"
     ]
    }
   ],
   "source": [
    "padded_dummy_conv=pad_size_one_kernel([dummy_conv])\n",
    "test_padded_kernel_conv(padded_dummy_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme précédemment, on vérifie via les développements limités que ça fonctionne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv, bn = fuse_bn_conv([padded_dummy_conv], batchnorm_variables(1,2,1,4,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999375"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = compute_scaling_weight_factor(1,4)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.isclose(conv, scale*padded_dummy_conv, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5000625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_scale = compute_scaling_bias_factor(1,2,1,4)\n",
    "bias_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_real = bias_scale*np.ones(16)\n",
    "np.mean(np.isclose(bn_real, bn, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "0pa3HAuZadQt"
   },
   "outputs": [],
   "source": [
    "weights_conv1 = model_before_fusion_conv1.get_layer('conv')\n",
    "weights_bn1 = model_before_fusion_conv1.get_layer('bn')\n",
    "\n",
    "padded_weights_conv1 = pad_size_one_kernel(weights_conv1.get_weights())\n",
    "conv_weights, conv_bias = fuse_bn_conv([padded_weights_conv1], weights_bn1.get_weights())\n",
    "\n",
    "model_after_fusion_conv1.get_layer(\"conv\").set_weights([conv_weights, conv_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion d'une $\\mathrm{id}$ en $\\mathrm{Conv} 3 \\times 3$ puis fusion avec la batchnorm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les branches id ne sont utilisées dans l'architecture de RepVGG que lorsque la conditions `channels_in` = `channels_out` est vérifiée, c'est à dire à l'intérieur de chaque stage entre 2 blocs convolutifs avec un stride de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixons le nombre de channels, peut importe le nombre.\n",
    "channels = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An identity mapping can be viewed as a $1\\times1$ conv with an identity matrix as the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "zal7-PzPg74V",
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def size_three_kernel_from_id(channels):\n",
    "    kernel = np.ones(channels)\n",
    "    kernel = np.diag(kernel)\n",
    "    kernel = np.reshape(kernel, (1,1,channels,channels))\n",
    "    kernel = np.pad(kernel, pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAlAll12kVRj",
    "outputId": "ccc7720b-af6a-43be-b095-2880d161a0df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 4, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_from_id = size_three_kernel_from_id(4)\n",
    "conv_from_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def test_padded_kernel_from_id(padded_kernel):\n",
    "    for i in range(3):\n",
    "        for j in range(16):\n",
    "            print(f'Matrix of size 3x3 : {padded_kernel[:,:,i,j].shape == (3,3)}')\n",
    "            squared_sum = 0\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    if (k,l) != (1,1):\n",
    "                        squared_sum += padded_kernel[:,:,i,j][k,l]**2\n",
    "                    else:\n",
    "                        print(f'Middle element is 1 : {padded_kernel[:,:,i,j][k,l]==1}')\n",
    "            print(f'Squared sum is : {squared_sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n"
     ]
    }
   ],
   "source": [
    "test_padded_kernel_from_id(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv, bn = fuse_bn_conv([conv_from_id], batchnorm_variables(1,2,1,4,channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999375"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = compute_scaling_weight_factor(1,4)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.isclose(conv, scale*conv_from_id, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5000625"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_scale = compute_scaling_bias_factor(1,2,1,4)\n",
    "bias_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_real = bias_scale*np.ones(channels)\n",
    "np.mean(np.isclose(bn_real, bn, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8AiIqCHo5hH"
   },
   "source": [
    "## Test grandeur réelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def repvgg_block(tensor, filters, num_layer):\n",
    "    \n",
    "    # main stream\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(3,3),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f'block_{num_layer}_conv_main'\n",
    "    )(tensor)\n",
    "    x = BatchNormalization(name=f'block_{num_layer}_bn_main')(x)\n",
    "    \n",
    "    # conv1x1 stream\n",
    "    \n",
    "    y = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(1,1),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f'block_{num_layer}_conv_alt'\n",
    "    )(tensor)\n",
    "    y = BatchNormalization(name=f'block_{num_layer}_bn_alt')(y)\n",
    "    \n",
    "    z = Add()([x,y])\n",
    "    \n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def repvgg_block_with_id(tensor, filters, num_layer):\n",
    "\n",
    "    # main stream\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f\"block_{num_layer}_conv_main\",\n",
    "    )(tensor)\n",
    "    x = BatchNormalization(name=f\"block_{num_layer}_bn_main\")(x)\n",
    "\n",
    "    # conv1x1 stream\n",
    "\n",
    "    y = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f\"block_{num_layer}_conv_alt\",\n",
    "    )(tensor)\n",
    "    y = BatchNormalization(name=f\"block_{num_layer}_bn_alt\")(y)\n",
    "\n",
    "    # id_conv branch\n",
    "    z = BatchNormalization(name=f\"block_{num_layer}_bn_id\")(tensor)\n",
    "\n",
    "    return Add()([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def get_model(img_shape):\n",
    "\n",
    "    input = Input(img_shape)\n",
    "    \n",
    "    x = repvgg_block(input, filters=64, num_layer=0)\n",
    "    x = ReLU()(x)\n",
    "    x = repvgg_block(x, filters=64, num_layer=1)\n",
    "    x = ReLU()(x)\n",
    "    x = repvgg_block_with_id(x, filters=64, num_layer=2)\n",
    "    x = ReLU()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, name='dense')(x)\n",
    "    x = Softmax()(x)\n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "def get_inference_model(img_shape):\n",
    "    input = Input(img_shape)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), padding='same', name='conv_0')(input)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), padding='same', name='conv_1')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', name='conv_2')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, name='dense')(x)\n",
    "    x = Softmax()(x)\n",
    "    model = Model(input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block_0_conv_main (Conv2D)      (None, 16, 16, 64)   1728        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_0_conv_alt (Conv2D)       (None, 16, 16, 64)   192         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_0_bn_main (BatchNormaliza (None, 16, 16, 64)   256         block_0_conv_main[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_0_bn_alt (BatchNormalizat (None, 16, 16, 64)   256         block_0_conv_alt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 64)   0           block_0_bn_main[0][0]            \n",
      "                                                                 block_0_bn_alt[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 16, 16, 64)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_main (Conv2D)      (None, 8, 8, 64)     36864       re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_alt (Conv2D)       (None, 8, 8, 64)     4096        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_bn_main (BatchNormaliza (None, 8, 8, 64)     256         block_1_conv_main[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_bn_alt (BatchNormalizat (None, 8, 8, 64)     256         block_1_conv_alt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 64)     0           block_1_bn_main[0][0]            \n",
      "                                                                 block_1_bn_alt[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 8, 8, 64)     0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_main (Conv2D)      (None, 8, 8, 64)     36864       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_alt (Conv2D)       (None, 8, 8, 64)     4096        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_2_bn_main (BatchNormaliza (None, 8, 8, 64)     256         block_2_conv_main[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_bn_alt (BatchNormalizat (None, 8, 8, 64)     256         block_2_conv_alt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_2_bn_id (BatchNormalizati (None, 8, 8, 64)     256         re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 64)     0           block_2_bn_main[0][0]            \n",
      "                                                                 block_2_bn_alt[0][0]             \n",
      "                                                                 block_2_bn_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 8, 8, 64)     0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 4096)         0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           40970       flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_6 (Softmax)             (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 126,602\n",
      "Trainable params: 125,706\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model = get_model([32,32,3])\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 16, 16, 64)        1792      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 116,618\n",
      "Trainable params: 116,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_model = get_inference_model([32,32,3])\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def from_repvgg_to_vgg(training_model, inference_model, depth):\n",
    "    model = training_model\n",
    "    inference_model = inference_model\n",
    "    \n",
    "    for i in range(depth):\n",
    "        print(f\"Fusion Conv-BN from main branch at depth {i}\")\n",
    "        conv_main = model.get_layer(f\"block_{i}_conv_main\")\n",
    "        bn_main = model.get_layer(f\"block_{i}_bn_main\")\n",
    "\n",
    "        conv_weights_main, conv_biases_main = fuse_bn_conv(\n",
    "            conv_main.get_weights(), bn_main.get_weights()\n",
    "        )\n",
    "\n",
    "        print(f\"Fusion Conv-BN from alt branch at depth {i}\")\n",
    "        conv_alt_one_by_one = model.get_layer(f\"block_{i}_conv_alt\")\n",
    "        bn_alt = model.get_layer(f\"block_{i}_bn_alt\")\n",
    "\n",
    "        conv_alt = pad_size_one_kernel(conv_alt_one_by_one.get_weights())\n",
    "\n",
    "        conv_weights_alt, conv_biases_alt = fuse_bn_conv([conv_alt], bn_alt.get_weights())\n",
    "        \n",
    "        if i==3:\n",
    "            print(f\"Fusion Conv-BN from id branch at depth {i}\")\n",
    "            bn_id = model.get_layer(f\"block_{i}_bn_id\")\n",
    "            channels = backend.int_shape(bn_id.get_weights()[0])[-1]\n",
    "\n",
    "            conv_id = size_three_kernel_from_id(channels)\n",
    "            conv_weights_id, conv_biases_id = fuse_bn_conv([conv_id], bn_id.get_weights())\n",
    "\n",
    "            conv_weights = conv_weights_main + conv_weights_alt + conv_weights_id\n",
    "            conv_biases = conv_biases_main + conv_biases_alt + conv_biases_id\n",
    "        else:\n",
    "            conv_weights = conv_weights_main + conv_weights_alt\n",
    "            conv_biases = conv_biases_main + conv_biases_alt\n",
    "            \n",
    "           \n",
    "        print(f\"Setting weights on inference model at depth {i}\")\n",
    "        inference_model.get_layer(f\"conv_{i}\").set_weights([conv_weights, conv_biases])\n",
    "\n",
    "    dense_weights = model.get_layer(f\"dense\").get_weights()\n",
    "    inference_model.get_layer(f\"dense\").set_weights(dense_weights)\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train,y_train), (X_test,y_test)  = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "X_train = X_train.reshape(-1, 32, 32, 3).astype('float32')\n",
    "X_test = X_test.reshape(-1, 32, 32, 3).astype('float32')\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "y_train_oh = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_oh = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "y_valid_oh = tf.keras.utils.to_categorical(y_valid, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 2s 4ms/step - loss: 1.9390 - accuracy: 0.3690 - val_loss: 1.4326 - val_accuracy: 0.4882\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 1.1761 - accuracy: 0.5805 - val_loss: 1.2776 - val_accuracy: 0.5559\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.9771 - accuracy: 0.6608 - val_loss: 1.2784 - val_accuracy: 0.5692\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.8457 - accuracy: 0.7047 - val_loss: 1.1538 - val_accuracy: 0.6070\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.7411 - accuracy: 0.7415 - val_loss: 1.1523 - val_accuracy: 0.6082\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.6627 - accuracy: 0.7721 - val_loss: 1.2050 - val_accuracy: 0.6056\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.5730 - accuracy: 0.8017 - val_loss: 1.3360 - val_accuracy: 0.5908\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.5037 - accuracy: 0.8267 - val_loss: 1.2697 - val_accuracy: 0.6086\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.8549 - val_loss: 1.6375 - val_accuracy: 0.5710\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.8732 - val_loss: 1.4501 - val_accuracy: 0.6078\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.8947 - val_loss: 1.3964 - val_accuracy: 0.6189\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.2657 - accuracy: 0.9140 - val_loss: 1.4346 - val_accuracy: 0.6252\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9247 - val_loss: 1.7435 - val_accuracy: 0.6030\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9402 - val_loss: 1.6220 - val_accuracy: 0.6197\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1661 - accuracy: 0.9486 - val_loss: 2.0838 - val_accuracy: 0.5826\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9539 - val_loss: 1.6913 - val_accuracy: 0.6221\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9603 - val_loss: 1.7873 - val_accuracy: 0.6273\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 1.9872 - val_accuracy: 0.6094\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9691 - val_loss: 2.0423 - val_accuracy: 0.6062\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9666 - val_loss: 2.0206 - val_accuracy: 0.6166\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0920 - accuracy: 0.9714 - val_loss: 2.0964 - val_accuracy: 0.6199\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9750 - val_loss: 2.4125 - val_accuracy: 0.5951\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9814 - val_loss: 2.2896 - val_accuracy: 0.6095\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0907 - accuracy: 0.9686 - val_loss: 2.3337 - val_accuracy: 0.6104\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9755 - val_loss: 2.7223 - val_accuracy: 0.5977\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9804 - val_loss: 2.3225 - val_accuracy: 0.6226\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0616 - accuracy: 0.9815 - val_loss: 2.3531 - val_accuracy: 0.6187\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9862 - val_loss: 2.5024 - val_accuracy: 0.6199\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 2.9272 - val_accuracy: 0.5823\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9745 - val_loss: 2.4670 - val_accuracy: 0.6142\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0780 - accuracy: 0.9733 - val_loss: 2.6590 - val_accuracy: 0.6194\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9776 - val_loss: 2.5846 - val_accuracy: 0.6173\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 2.5448 - val_accuracy: 0.6227\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 2.6284 - val_accuracy: 0.6238\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 2.8331 - val_accuracy: 0.6170\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9809 - val_loss: 3.3461 - val_accuracy: 0.5866\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0740 - accuracy: 0.9740 - val_loss: 2.9504 - val_accuracy: 0.6025\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9749 - val_loss: 2.7457 - val_accuracy: 0.6227\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9849 - val_loss: 2.7979 - val_accuracy: 0.6226\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9929 - val_loss: 2.8238 - val_accuracy: 0.6207\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 2.8020 - val_accuracy: 0.6298\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 2.8443 - val_accuracy: 0.6261\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9870 - val_loss: 4.3773 - val_accuracy: 0.5440\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9646 - val_loss: 3.0375 - val_accuracy: 0.6030\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9799 - val_loss: 2.8326 - val_accuracy: 0.6314\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 2.8987 - val_accuracy: 0.6274\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 2.9066 - val_accuracy: 0.6258\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 3.0005 - val_accuracy: 0.6267\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 2.9672 - val_accuracy: 0.6337\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 3.4715 - val_accuracy: 0.5854\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9634 - val_loss: 3.1194 - val_accuracy: 0.6069\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 3.4825 - val_accuracy: 0.6022\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 3.1542 - val_accuracy: 0.6277\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 3.0385 - val_accuracy: 0.6305\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 3.0361 - val_accuracy: 0.6351\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 3.0368 - val_accuracy: 0.6361\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 3.1196 - val_accuracy: 0.6257\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 3.2946 - val_accuracy: 0.6184\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9726 - val_loss: 3.6981 - val_accuracy: 0.5838\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9615 - val_loss: 3.3662 - val_accuracy: 0.6150\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 3.1085 - val_accuracy: 0.6268\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 3.2636 - val_accuracy: 0.6290\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 3.1850 - val_accuracy: 0.6310\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 3.2820 - val_accuracy: 0.6345\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 3.1574 - val_accuracy: 0.6397\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1854 - val_accuracy: 0.6414\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1196 - val_accuracy: 0.6458\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.6865e-04 - accuracy: 1.0000 - val_loss: 3.1958 - val_accuracy: 0.6469\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.6404e-04 - accuracy: 1.0000 - val_loss: 3.1414 - val_accuracy: 0.6472\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.8577e-04 - accuracy: 1.0000 - val_loss: 3.1648 - val_accuracy: 0.6446\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.2701e-04 - accuracy: 1.0000 - val_loss: 3.2118 - val_accuracy: 0.6478\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9627 - val_loss: 3.3232 - val_accuracy: 0.5995\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1219 - accuracy: 0.9585 - val_loss: 3.0879 - val_accuracy: 0.6179\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 3.1610 - val_accuracy: 0.6290\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 3.0288 - val_accuracy: 0.6348\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 3.0254 - val_accuracy: 0.6465\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 3.0743 - val_accuracy: 0.6470\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 3.1198 - val_accuracy: 0.6430\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0889 - val_accuracy: 0.6466\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.1780 - val_accuracy: 0.6393\n",
      "Epoch 81/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1530 - val_accuracy: 0.6427\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.9041e-04 - accuracy: 1.0000 - val_loss: 3.1667 - val_accuracy: 0.6454\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.6558e-04 - accuracy: 1.0000 - val_loss: 3.1835 - val_accuracy: 0.6430\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9710 - val_loss: 4.0625 - val_accuracy: 0.5772\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1073 - accuracy: 0.9622 - val_loss: 3.1034 - val_accuracy: 0.6308\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 3.1997 - val_accuracy: 0.6258\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 3.2102 - val_accuracy: 0.6319\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 3.1613 - val_accuracy: 0.6379\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 3.2062 - val_accuracy: 0.6387\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 3.1607 - val_accuracy: 0.6414\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1905 - val_accuracy: 0.6446\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 3.2038 - val_accuracy: 0.6442\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 3.2732 - val_accuracy: 0.6409\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 7.5633e-04 - accuracy: 1.0000 - val_loss: 3.2499 - val_accuracy: 0.6442\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 7.7323e-04 - accuracy: 1.0000 - val_loss: 3.2885 - val_accuracy: 0.6450\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.9023e-04 - accuracy: 1.0000 - val_loss: 3.4087 - val_accuracy: 0.6306\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 5.3897 - val_accuracy: 0.5452\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.9175 - val_loss: 3.8454 - val_accuracy: 0.5955\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 3.4719 - val_accuracy: 0.6225\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 3.4143 - val_accuracy: 0.6262\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 3.2489 - val_accuracy: 0.6374\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 3.2455 - val_accuracy: 0.6399\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2159 - val_accuracy: 0.6434\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2219 - val_accuracy: 0.6451\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2600 - val_accuracy: 0.6425\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.9068e-04 - accuracy: 1.0000 - val_loss: 3.2839 - val_accuracy: 0.6430\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 8.8232e-04 - accuracy: 1.0000 - val_loss: 3.2854 - val_accuracy: 0.6457\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3356e-04 - accuracy: 1.0000 - val_loss: 3.3021 - val_accuracy: 0.6451\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.9747e-04 - accuracy: 1.0000 - val_loss: 3.3147 - val_accuracy: 0.6457\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.3339e-04 - accuracy: 1.0000 - val_loss: 3.3380 - val_accuracy: 0.6454\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 4.3812e-04 - accuracy: 1.0000 - val_loss: 3.3765 - val_accuracy: 0.6447\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.1380e-04 - accuracy: 1.0000 - val_loss: 3.3854 - val_accuracy: 0.6460\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.5256e-04 - accuracy: 1.0000 - val_loss: 3.4450 - val_accuracy: 0.6454\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9867 - val_loss: 3.9023 - val_accuracy: 0.5873\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9468 - val_loss: 3.3988 - val_accuracy: 0.6180\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 3.3156 - val_accuracy: 0.6344\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 3.2564 - val_accuracy: 0.6354\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 3.3034 - val_accuracy: 0.6414\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 3.3015 - val_accuracy: 0.6431\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 3.3338 - val_accuracy: 0.6422\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3000 - val_accuracy: 0.6458\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 9.2647e-04 - accuracy: 1.0000 - val_loss: 3.3178 - val_accuracy: 0.6457\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 8.6534e-04 - accuracy: 1.0000 - val_loss: 3.3308 - val_accuracy: 0.6482\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3539e-04 - accuracy: 1.0000 - val_loss: 3.3759 - val_accuracy: 0.6479\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.1540e-04 - accuracy: 1.0000 - val_loss: 3.3861 - val_accuracy: 0.6474\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.1956e-04 - accuracy: 1.0000 - val_loss: 3.3955 - val_accuracy: 0.6460\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.9951e-04 - accuracy: 1.0000 - val_loss: 3.5187 - val_accuracy: 0.6467\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 4.4000 - val_accuracy: 0.5709\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.2555 - accuracy: 0.9294 - val_loss: 3.7346 - val_accuracy: 0.6086\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 3.4413 - val_accuracy: 0.6241\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 3.4731 - val_accuracy: 0.6366\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 3.3815 - val_accuracy: 0.6391\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 3.4015 - val_accuracy: 0.6413\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 3.4036 - val_accuracy: 0.6428\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.4494 - val_accuracy: 0.6402\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 3.4177 - val_accuracy: 0.6470\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.6482e-04 - accuracy: 1.0000 - val_loss: 3.4614 - val_accuracy: 0.6452\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.2557e-04 - accuracy: 1.0000 - val_loss: 3.4649 - val_accuracy: 0.6465\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.4032e-04 - accuracy: 1.0000 - val_loss: 3.4694 - val_accuracy: 0.6444\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.6854e-04 - accuracy: 1.0000 - val_loss: 3.5629 - val_accuracy: 0.6450\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.7389e-04 - accuracy: 1.0000 - val_loss: 3.5976 - val_accuracy: 0.6391\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.9803 - val_loss: 3.6825 - val_accuracy: 0.6078\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9660 - val_loss: 3.4045 - val_accuracy: 0.6313\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 3.5080 - val_accuracy: 0.6366\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 3.4096 - val_accuracy: 0.6414\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 3.4737 - val_accuracy: 0.6436\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 3.5510 - val_accuracy: 0.6415\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 3.5113 - val_accuracy: 0.6454\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4949 - val_accuracy: 0.6440\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 3.5232 - val_accuracy: 0.6479\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.0308e-04 - accuracy: 1.0000 - val_loss: 3.5569 - val_accuracy: 0.6500\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.7638e-04 - accuracy: 1.0000 - val_loss: 3.5668 - val_accuracy: 0.6485\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3473e-04 - accuracy: 1.0000 - val_loss: 3.5986 - val_accuracy: 0.6502\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.5041e-04 - accuracy: 1.0000 - val_loss: 3.5845 - val_accuracy: 0.6482\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.0400e-04 - accuracy: 1.0000 - val_loss: 3.6154 - val_accuracy: 0.6446\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3062e-04 - accuracy: 1.0000 - val_loss: 3.7590 - val_accuracy: 0.6394\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9545 - val_loss: 3.6780 - val_accuracy: 0.6218\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 3.5992 - val_accuracy: 0.6316\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 3.7416 - val_accuracy: 0.6269\n",
      "Epoch 160/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 3.5675 - val_accuracy: 0.6382\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 3.6239 - val_accuracy: 0.6394\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 3.5901 - val_accuracy: 0.6389\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 3.6193 - val_accuracy: 0.6441\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 3.6285 - val_accuracy: 0.6438\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 7.3676e-04 - accuracy: 1.0000 - val_loss: 3.6237 - val_accuracy: 0.6454\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.4252e-04 - accuracy: 1.0000 - val_loss: 3.6783 - val_accuracy: 0.6441\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.7206e-04 - accuracy: 1.0000 - val_loss: 3.6587 - val_accuracy: 0.6457\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.1652e-04 - accuracy: 1.0000 - val_loss: 3.6578 - val_accuracy: 0.6467\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 4.2009 - val_accuracy: 0.5858\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9697 - val_loss: 3.5935 - val_accuracy: 0.6283\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 3.6487 - val_accuracy: 0.6332\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 3.8405 - val_accuracy: 0.6329\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 3.6509 - val_accuracy: 0.6421\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 3.6520 - val_accuracy: 0.6394\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.6577 - val_accuracy: 0.6406\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.8113e-04 - accuracy: 1.0000 - val_loss: 3.6778 - val_accuracy: 0.6417\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.0387e-04 - accuracy: 1.0000 - val_loss: 3.6704 - val_accuracy: 0.6414\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.4948e-04 - accuracy: 1.0000 - val_loss: 3.7070 - val_accuracy: 0.6417\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 4.2156e-04 - accuracy: 1.0000 - val_loss: 3.7131 - val_accuracy: 0.6404\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.7091e-04 - accuracy: 1.0000 - val_loss: 3.8784 - val_accuracy: 0.6346\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0651 - accuracy: 0.9804 - val_loss: 4.3902 - val_accuracy: 0.5985\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0633 - accuracy: 0.9788 - val_loss: 4.0795 - val_accuracy: 0.6162\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 4.0404 - val_accuracy: 0.6267\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 3.7312 - val_accuracy: 0.6357\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 3.7239 - val_accuracy: 0.6436\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 3.7600 - val_accuracy: 0.6344\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 3.7408 - val_accuracy: 0.6391\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 3.8037 - val_accuracy: 0.6379\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 3.8553 - val_accuracy: 0.6378\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 4.3736 - val_accuracy: 0.6046\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9757 - val_loss: 4.1114 - val_accuracy: 0.6099\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9879 - val_loss: 4.0255 - val_accuracy: 0.6281\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 3.9506 - val_accuracy: 0.6345\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 3.9339 - val_accuracy: 0.6302\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 3.8998 - val_accuracy: 0.6373\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 3.8751 - val_accuracy: 0.6438\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.7056e-04 - accuracy: 1.0000 - val_loss: 3.8705 - val_accuracy: 0.6424\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.4642e-04 - accuracy: 1.0000 - val_loss: 3.8781 - val_accuracy: 0.6441\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.2847e-04 - accuracy: 1.0000 - val_loss: 3.8988 - val_accuracy: 0.6422\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.0220e-04 - accuracy: 1.0000 - val_loss: 3.9146 - val_accuracy: 0.6449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc892648ca0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "training_model.fit(X_train, y_train_oh,\n",
    "                     epochs = 200,\n",
    "                     batch_size=128,\n",
    "                     validation_data=(X_valid, y_valid_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 4.0375 - accuracy: 0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.037524223327637, 0.6407999992370605]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.evaluate(X_test, y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Conv-BN from main branch at depth 0\n",
      "Fusion Conv-BN from alt branch at depth 0\n",
      "Setting weights on inference model at depth 0\n",
      "Fusion Conv-BN from main branch at depth 1\n",
      "Fusion Conv-BN from alt branch at depth 1\n",
      "Setting weights on inference model at depth 1\n",
      "Fusion Conv-BN from main branch at depth 2\n",
      "Fusion Conv-BN from alt branch at depth 2\n",
      "Setting weights on inference model at depth 2\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 16, 16, 64)        1792      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 116,618\n",
      "Trainable params: 116,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = from_repvgg_to_vgg(training_model, inference_model, 3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.SGD(lr=2e-9),\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 7.8139 - accuracy: 0.3986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.867744445800781, 0.39640000462532043]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fusion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
