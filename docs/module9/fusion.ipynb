{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion Conv-BN et RepVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r1pY7xYhCLKe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalAvgPool2D, Flatten, ReLU, Softmax, Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Add\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = 32, 32, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des poids des Conv $3 \\times 3$ et des BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons comment s'articulent les poids dans les couches de convolutions et de batchnormalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation d'un mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zA17F4n2CRmb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "testing_conv_init (Conv2D)   (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "testing_bn_init (BatchNormal (None, 32, 32, 16)        64        \n",
      "=================================================================\n",
      "Total params: 512\n",
      "Trainable params: 480\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=True, kernel_initializer='he_uniform', name='testing_conv_init')(input)\n",
    "x= BatchNormalization(name=f'testing_bn_init')(x)\n",
    "model = Model(input, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude de la couche convolutive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[-0.09736294,  0.01110744,  0.38817808,  0.02365676,\n",
       "            0.37265095,  0.22067323,  0.44893858, -0.4457162 ,\n",
       "            0.2723634 ,  0.21101996, -0.42767352,  0.39105812,\n",
       "           -0.38641602, -0.39619464, -0.12856498,  0.00230291],\n",
       "          [-0.15622476,  0.08576027, -0.39533868,  0.14336786,\n",
       "            0.09569708,  0.05594608,  0.05045763, -0.15595007,\n",
       "           -0.05612397, -0.19001147,  0.2724487 ,  0.3459774 ,\n",
       "            0.01586419,  0.08192965,  0.32559904,  0.04557905],\n",
       "          [-0.37503266,  0.05977681, -0.05365878,  0.34279034,\n",
       "           -0.22699383, -0.20862746,  0.13931164, -0.20776296,\n",
       "            0.12117836,  0.06501201, -0.28448707,  0.2668244 ,\n",
       "            0.2704514 , -0.34608564, -0.35193035, -0.3525829 ]],\n",
       " \n",
       "         [[ 0.11737838,  0.14824674, -0.00563487,  0.3061553 ,\n",
       "            0.01097953,  0.23561516, -0.4535907 , -0.4175086 ,\n",
       "            0.4607807 , -0.37212858, -0.30806714,  0.14160755,\n",
       "            0.24837866,  0.12601265,  0.2622976 ,  0.3263745 ],\n",
       "          [-0.34101892,  0.31189194, -0.11391068,  0.14759234,\n",
       "           -0.30657652, -0.13771534,  0.45230624,  0.22417751,\n",
       "            0.0407432 ,  0.07712099, -0.2991236 , -0.1449846 ,\n",
       "           -0.00576615,  0.26184592, -0.2169587 , -0.2828556 ],\n",
       "          [-0.20167324, -0.1357314 , -0.29285318,  0.33294716,\n",
       "            0.23413381, -0.00896761, -0.31519616,  0.14762929,\n",
       "           -0.18309683, -0.32602823,  0.10732868, -0.15018934,\n",
       "           -0.27001262,  0.0079852 , -0.20946455, -0.10388163]],\n",
       " \n",
       "         [[ 0.2783232 ,  0.05878171, -0.35913152,  0.40182415,\n",
       "            0.092141  , -0.13399044,  0.03964153,  0.06443217,\n",
       "            0.46447167, -0.41376618,  0.10037312,  0.42862818,\n",
       "            0.17965165, -0.13864604,  0.04373595, -0.13044247],\n",
       "          [-0.45564812, -0.33004287,  0.3405182 ,  0.39920047,\n",
       "           -0.25907567,  0.15346971, -0.02812734, -0.19346526,\n",
       "           -0.12104025, -0.4278583 ,  0.23774037,  0.3617756 ,\n",
       "           -0.0419741 ,  0.09765604, -0.26489764, -0.43987206],\n",
       "          [ 0.07685599,  0.04646841, -0.06539023,  0.02657837,\n",
       "            0.44154963,  0.21664849,  0.4601402 ,  0.21062568,\n",
       "            0.34529766,  0.30855897,  0.40019926, -0.26326853,\n",
       "           -0.04224968, -0.46108606, -0.37318596, -0.42175823]]],\n",
       " \n",
       " \n",
       "        [[[-0.3455502 ,  0.46076384, -0.15374777,  0.29009756,\n",
       "           -0.1667389 ,  0.31607136,  0.26514402,  0.3037739 ,\n",
       "           -0.0812335 ,  0.23732015,  0.07654181, -0.0679315 ,\n",
       "           -0.31959674, -0.28597334, -0.10885993,  0.408551  ],\n",
       "          [ 0.14297041, -0.09827566,  0.40382537, -0.4178524 ,\n",
       "           -0.01861295, -0.35064167,  0.45108077, -0.12225789,\n",
       "           -0.29017037,  0.23471412,  0.14587566, -0.36702543,\n",
       "           -0.3979674 ,  0.29743996, -0.39642572, -0.0245271 ],\n",
       "          [-0.0504581 ,  0.46684763,  0.37567046,  0.20170256,\n",
       "           -0.36068565, -0.17110959,  0.30896595,  0.09373525,\n",
       "           -0.21380827, -0.395913  ,  0.24522027,  0.36945108,\n",
       "           -0.06558827, -0.4528262 ,  0.08612862,  0.3769413 ]],\n",
       " \n",
       "         [[-0.06688267,  0.11741361, -0.14751217, -0.01143798,\n",
       "            0.30352488,  0.23946908,  0.15358987, -0.11050937,\n",
       "           -0.05894232, -0.22810066,  0.3403059 ,  0.23961261,\n",
       "           -0.16434652,  0.11093548,  0.00398877, -0.11645409],\n",
       "          [-0.37574512,  0.3296124 , -0.05067682, -0.09595928,\n",
       "           -0.2214837 ,  0.35080925, -0.02972579,  0.1532239 ,\n",
       "            0.18751535, -0.02314931, -0.18395177, -0.03616032,\n",
       "            0.27149966, -0.4180094 ,  0.28113106,  0.4416559 ],\n",
       "          [-0.2833048 ,  0.03007612,  0.34248617, -0.24044934,\n",
       "            0.16455218,  0.15701613,  0.20851544, -0.25038487,\n",
       "           -0.21328565, -0.23982422,  0.37252668,  0.15518335,\n",
       "            0.28911796,  0.44327244,  0.14157644,  0.26580074]],\n",
       " \n",
       "         [[ 0.28428563, -0.18229985, -0.20275667,  0.1955097 ,\n",
       "           -0.3543805 , -0.14616191,  0.28929475,  0.14749238,\n",
       "            0.2464734 , -0.46400836, -0.02009585,  0.3317866 ,\n",
       "           -0.20362425, -0.42040807, -0.17440939, -0.01986095],\n",
       "          [ 0.44240263,  0.1606206 , -0.4160647 ,  0.27185783,\n",
       "            0.06790957, -0.32414603, -0.23126818, -0.29003426,\n",
       "            0.12488225,  0.16395304, -0.3259102 , -0.38798535,\n",
       "           -0.43922648, -0.3790248 ,  0.12847778,  0.13634267],\n",
       "          [-0.02119684,  0.28930375, -0.4681574 ,  0.28300878,\n",
       "            0.40201846,  0.1442084 ,  0.19728747, -0.02722415,\n",
       "            0.42741737, -0.21063939,  0.42403385,  0.3592575 ,\n",
       "           -0.20373034, -0.4468028 , -0.08656737, -0.20087367]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02782702,  0.01967528,  0.07292607,  0.389165  ,\n",
       "            0.36987802,  0.18188533,  0.04504755,  0.41210625,\n",
       "            0.01592982, -0.11140019, -0.11948159,  0.10680953,\n",
       "           -0.11324027,  0.39144352, -0.35009858,  0.26030532],\n",
       "          [ 0.09090939, -0.09534436,  0.03001484, -0.1512312 ,\n",
       "           -0.3052565 ,  0.3308485 , -0.24254534, -0.10194659,\n",
       "            0.00120181,  0.38111654,  0.21856287,  0.32130632,\n",
       "           -0.33506405,  0.44324157,  0.32223514, -0.2681678 ],\n",
       "          [ 0.4114515 , -0.40250486,  0.3429939 , -0.2685476 ,\n",
       "            0.37336466,  0.18623039, -0.23775014,  0.18628749,\n",
       "           -0.07814869,  0.15818772, -0.21979165, -0.44143543,\n",
       "           -0.09982735, -0.17906868, -0.11419335, -0.10601136]],\n",
       " \n",
       "         [[-0.04968157,  0.33098873, -0.35580167,  0.19270661,\n",
       "            0.33699194,  0.41285995,  0.23392567,  0.4191365 ,\n",
       "           -0.04616675,  0.22136435, -0.29591143,  0.20710972,\n",
       "           -0.3502412 , -0.10524371, -0.32441103,  0.35304728],\n",
       "          [-0.45383817, -0.21678528,  0.13484439, -0.23379093,\n",
       "           -0.038737  ,  0.02832112, -0.36996582, -0.19088644,\n",
       "            0.32281145,  0.14254984,  0.24848273,  0.3904991 ,\n",
       "           -0.41010976, -0.4470079 , -0.13003865, -0.41824162],\n",
       "          [ 0.14215276,  0.29101995, -0.40439036, -0.43802816,\n",
       "            0.33089224, -0.34787324,  0.32901898, -0.11648187,\n",
       "           -0.07495171,  0.4408585 ,  0.24113259, -0.08504415,\n",
       "            0.0623028 ,  0.23243883, -0.19044554,  0.3553057 ]],\n",
       " \n",
       "         [[-0.09105429,  0.30605808,  0.41014054,  0.33675548,\n",
       "           -0.05541334,  0.1684458 , -0.12973395, -0.1533834 ,\n",
       "           -0.00280687, -0.07284549,  0.35922107,  0.09879085,\n",
       "            0.43200687,  0.02035648,  0.36917636, -0.4091605 ],\n",
       "          [-0.22962008,  0.13721845, -0.12232229, -0.2520702 ,\n",
       "            0.07350466,  0.042968  ,  0.31936017,  0.36257067,\n",
       "           -0.10858962, -0.18460804, -0.1590521 , -0.47047156,\n",
       "           -0.1503287 , -0.04001006, -0.11763006, -0.24719194],\n",
       "          [-0.32062727,  0.13543853,  0.0306963 , -0.16442779,\n",
       "           -0.37330386,  0.13838956,  0.03568128, -0.2321063 ,\n",
       "            0.07501194, -0.426333  ,  0.00162551,  0.04697415,\n",
       "           -0.20748636, -0.30767232,  0.43708238, -0.16146705]]]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv = model.get_layer(\"testing_conv_init\").get_weights()\n",
    "weights_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids forment une liste de deux √©lements : les poids des noyaux de convolutions et les biais. La m√©thode d'initalisation utilis√©e ici est `he_uniform`, d√©velopp√©e dans l'article [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les poids dans une couche convolutive sont une liste de deux √©l√©ments : \n",
    "- `weights[0]` correspond aux poids des noyaux de convolution,\n",
    "- `weights[1]` correspond aux biais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights_conv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQ5L4FtrD6ei",
    "outputId": "8b874cef-55bd-43e3-cbe7-947ab9ef8cd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[0].shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les axes du tenseur de poids suivent les dimensions suivantes :\n",
    "\n",
    "- kernel_size1 : hauteur du kernel,\n",
    "- kernel_size2 : largeur du kernel,\n",
    "- channels_in : nombre des feature maps en entr√©e, \n",
    "- channels_out : nombres de features maps (filters) en sortie.\n",
    "\n",
    "`channels_out` est d√©finie dans la couche convolutive via le param√®tres `filters`, alors que la valeur `channels_in` est elle directement d√©termin√©e par le tenseur en entr√©e. C'est une diff√©rence de TensorFlow par rapport √† Pytorch o√π `channels_in` et `channels_out` sont tous les deux des param√®tres des couches convolutives.\n",
    "\n",
    "Ainsi, si l'on veut voir les poids du noyau de convolution par rapport au canal $0$ en la feature map de sortie $5$, on les obtient en regardant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22067323,  0.23561516, -0.13399044],\n",
       "       [ 0.31607136,  0.23946908, -0.14616191],\n",
       "       [ 0.18188533,  0.41285995,  0.1684458 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[0][:,:,0,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©faut, les biais des couches de convolutions sont tous initialis√©s √† z√©ro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude de la batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_bn = model.get_layer('testing_bn_init').get_weights()\n",
    "weights_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weights_bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans une couche de Batchnormalization, on a 4 types de poids.\n",
    "\n",
    "- Les deux param√®tres de scaling $\\gamma$ et de biais $\\beta$.\n",
    "- Les deux param√®tres correspondant √† la moyenne $\\mu$ et la variance $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous ces param√®tres ne sont pas entra√Ænables, comme on peut le voir dans la liste suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(var.name, var.trainable) for var in model.get_layer('testing_bn_init').variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 4, 16], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend.shape(model.get_layer('testing_bn_init').get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les $4$ param√®tres sont tous des vecteurs de dimension $16$, ce qui correspond au nombre de feature maps en sortie de la couche convolutive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion d'une Convolution et d'une batchnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fusion d'une couche de convolution avec une couche de batchnorm ressort les poids et biais d'une nouvelle couche de convolution avec les noyaux de convolutions de m√™me dimension.\n",
    "\n",
    "Etant donn√© le tenseur $W$ de poids des noyaux de convolution d'une couche convolutive et le tenseur de $4$ param√®tres $B=(\\gamma, \\beta, \\mu, \\sigma)$ d'une couche de batchnormalization, on obtient les nouveaux poids et poids de la nouvelle couche convolutive via les formules suivantes.\n",
    "\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{\\gamma_{j} \\cdot W_{:,:,:,j}}{\\sqrt{\\sigma_{j} + \\epsilon}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "b_{j} = \\beta_{j} - \\frac{\\mu_{j}\\cdot\\gamma_{j}}{\\sqrt{\\sigma_{j} + \\epsilon}} \n",
    "$$\n",
    "\n",
    "On remarque ici que le biais de la nouvelle couche de convolution ne d√©pend que des param√®tres de la couche de batchnorm. **Ce qui est coh√©rent avec la pratique de ne jamais mettre de biais dans une couche de convolution lorsqu'elle est suivie par une couche de batchnorm**.\n",
    "\n",
    "\n",
    "**Remarque** : le $\\epsilon$ pr√©sent ici est pour s'assurer que l'on ne divise jamais pas z√©ro, dans la pratique il est fix√© √† $0,001$.\n",
    "\n",
    "Ce qui nous donne, dans la pratique la fonction suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bHoHvowwHAor",
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "# https://scortex.io/batch-norm-folding-an-easy-way-to-improve-your-network-speed/\n",
    "# https://github.com/DingXiaoH/RepVGG/blob/4da799e33c890c624bfb484b2c35abafd327ba40/repvgg.py#L68\n",
    "\n",
    "def fuse_bn_conv(weights_conv, weights_bn, eps=0.001):\n",
    "    gamma = np.reshape(weights_bn[0], (1,1,1,weights_bn[0].shape[0]))\n",
    "    beta = weights_bn[1]\n",
    "    mean = weights_bn[2]\n",
    "    variance = np.reshape(weights_bn[3], (1,1,1,weights_bn[3].shape[0]))\n",
    "\n",
    "    new_weights = (weights_conv[0]*gamma) / np.sqrt(variance + eps)\n",
    "    new_bias = beta - mean*gamma/np.sqrt(variance+eps)\n",
    "\n",
    "    new_bias = np.reshape(new_bias, weights_bn[3].shape[0])\n",
    "\n",
    "    return new_weights, new_bias\n",
    "\n",
    "# In the code above, the reshaping is necessary to prevent a mistake if the dimension of the output O was the same as the dimension of the input I. \n",
    "\n",
    "# def get_equivalent_kernel_bias(self):\n",
    "#    kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
    "#    kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
    "#    kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
    "#    return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D√©taillons la fonction ci dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouveau tenseur de poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discutons premi√®rement de la formulation du nouveau tenseur de poids, et voyons pourquoi on modifie la forme de vecteurs $\\gamma$ et $\\sigma$.\n",
    "\n",
    "$W_{:,:,:,j}$ correspond dans la formule au noyau de convolution complet de la $j$-i√®me feature map de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv = model.get_layer(\"testing_conv_init\").get_weights()\n",
    "weights_conv[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a $16$ noyaux de convolution, chacun de dimensions $(3,3,3)$. Par exemple, pour $j=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv[0][:,:,:,1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les vecteur $\\gamma$ et $\\sigma$ √©tant des vecteurs de dimension $16$, on va les \"transformer en tenseur\" de dimensions $(1,1,1,16)$ pour bien faire correspondre le produit suivant chaque axe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = np.reshape(weights_bn[3], (1,1,1,weights_bn[3].shape[0]))\n",
    "variance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = np.reshape(weights_bn[0], (1,1,1,weights_bn[0].shape[0]))\n",
    "gamma.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screen](images/fuse_conv_bn.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au final, la formule\n",
    "\n",
    "```python\n",
    "new_weights = (weights_conv[0]*gamma) / np.sqrt(variance + eps)\n",
    "```\n",
    "\n",
    "r√©sume tout cela, tous les tenseurs ayant le nombre d'axes, les op√©rations sont vectoris√©es et se font axe par axe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouveau tenseur de biais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlACrpn5JS_1",
    "outputId": "ce7f2944-5f0a-43bb-ca92-af9dd100b362"
   },
   "source": [
    "Le op√©rations de `reshape` n'ont pas ajouter de nouveaux scalaires, juste des axes, le calcul du biais se fait alors √©l√©ment par √©l√©ment pour tout $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V√©rification via les d√©veloppements limit√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cr√©ons un tenseur de poids $W$ rep√©resentatif du noyau d'une convolution et un tenseur de poids $B=(\\gamma, \\beta, \\mu, \\sigma)$ repr√©sentatif des coefficients d'une batchnormalization.\n",
    "\n",
    "Pour v√©rifier si tout marche bien, fixons volontairement le tenseur poids comme un tenseur de dimensions $(3,3,4,5)$, la dimension du noyau est toujours fix√© √† $(3,3)$ dans RepVGG, seules les dimensions `channels_in` et `channels_out` peuvent changer.\n",
    "\n",
    "Tous les coefficients du tenseur de poids seront fix√©s √† $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 4, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_weights = np.ones(3*3*4*5).reshape((3,3,4,5))\n",
    "conv_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimension `channels_out` ayant √©t√© fix√©e √† $5$, les vecteurs de la batchnormalization seront tous des vecteurs de dimension $5$. Fixons les coefficients suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def batchnorm_variables(gamma_coef: float, beta_coef: float, mu_coef: float, sigma_coef: float, channels: int):\n",
    "    gamma = gamma_coef*np.ones(channels)\n",
    "    beta = beta_coef*np.ones(channels)\n",
    "    mu = mu_coef*np.ones(channels)\n",
    "    sigma = sigma_coef*np.ones(channels)\n",
    "    \n",
    "    return [gamma, beta, mu, sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv, bn = fuse_bn_conv([conv_weights], batchnorm_variables(1,2,1,4,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par d√©finition, le nouveau tenseur de poids $\\widehat{W}$ de la convolution r√©sultant de la fusion de l'ancienne convolution et de la batchnorm est donn√© par formule suivante.\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{\\gamma_{j} \\cdot W_{:,:,:,j}}{\\sqrt{\\sigma_{j} + \\epsilon}}\n",
    "$$\n",
    "\n",
    "De fa√ßon g√©n√©rale, pour $\\gamma_{j}, \\sigma_{j}$, on a le d√©veloppement limit√© suivant.\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{\\gamma_{j} \\cdot W_{:,:,:,j}}{\\sqrt{\\sigma_{j} + \\epsilon}} = \\frac{\\gamma_{j}}{\\sqrt{\\sigma_{j}}}\\left[1- \\frac{1}{2\\sigma_{j}}\\epsilon + o(\\epsilon^{2})\\right]W_{:,:,:,j} \n",
    "$$\n",
    "\n",
    "Dans notre cas, $\\forall j, \\gamma_{j} = 1, \\sigma_{j} = 4$ d'o√π\n",
    "\n",
    "$$\n",
    "\\widehat{W}_{:,:,:,j} := \\frac{W_{:,:,:,j}}{\\sqrt{4 + \\epsilon}} = \\left[\\frac{1}{2}- \\frac{1}{16}\\epsilon + o(\\epsilon^{2})\\right]W_{:,:,:,j} \\simeq \\left[\\frac{1}{2}- \\frac{1}{16}\\epsilon\\right]W_{:,:,:,j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_scaling_weight_factor(gamma, sigma):\n",
    "    return gamma/np.sqrt(sigma)*(1-0.001/(2*sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = compute_scaling_weight_factor(1,4)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751]],\n",
       "\n",
       "       [[0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751]],\n",
       "\n",
       "       [[0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751],\n",
       "        [0.49993751, 0.49993751, 0.49993751, 0.49993751]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv[:,:,:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui correspond bien √† l'approximation obtenue par d√©veloppement limit√©. On peut par exemple v√©rifier si $\\widehat{W}$ est approximativement √©gal √† `conv` √† $10^{-3}$ avec la commande `np.isclose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375]],\n",
       "\n",
       "       [[0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375]],\n",
       "\n",
       "       [[0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375],\n",
       "        [0.4999375, 0.4999375, 0.4999375, 0.4999375]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_weights_real = scale*np.ones(3*3*4*5).reshape((3,3,4,5))\n",
    "conv_weights_real[:,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si `np.mean(...)` $< 1$ alors le calcul est faux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.isclose(conv, conv_weights_real, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le biais, on a la formule suivante.\n",
    "\n",
    "$$\n",
    "b_{j} = \\beta_{j} - \\frac{\\mu_{j}\\cdot\\gamma_{j}}{\\sqrt{\\sigma_{j} + \\epsilon}} = \\beta_{j} - \\frac{\\mu_{j}\\cdot\\gamma_{j}}{\\sqrt{\\sigma_{j}}}\\left[1- \\frac{1}{2\\sigma_{j}}\\epsilon + o(\\epsilon^{2})\\right]\n",
    "$$\n",
    "\n",
    "dans notre cas, on a :\n",
    "\n",
    "- $\\beta_{j} = 2$,\n",
    "- $\\gamma_{j} = 1$,\n",
    "- $\\mu_{j} = 1$,\n",
    "- $\\sigma_{j} = 4$.\n",
    "\n",
    "$$\n",
    "b_{j} = 2 - \\frac{1}{2}\\left[1- \\frac{1}{8}\\epsilon + o(\\epsilon^{2})\\right] \\simeq 2 - \\frac{1}{2} - \\frac{1}{16}\\epsilon\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_scaling_bias_factor(gamma, beta, mu, sigma):\n",
    "    a = (mu*gamma)/np.sqrt(sigma)\n",
    "    b = 1 - 0.001/(2*sigma)\n",
    "    \n",
    "    return beta-a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_scale = compute_scaling_bias_factor(1,2,1,4)\n",
    "bias_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.50006249, 1.50006249, 1.50006249, 1.50006249, 1.50006249])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_real = bias_scale*np.ones(5)\n",
    "np.mean(np.isclose(bn_real, bn, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RepVGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screen](./images/repvgg.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screen](./images/repvgg2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les couches convolutives dans RepVGG n'ayant que des noyaux $3\\times3$ ou $1\\times1$, on ne se pr√©occupe que de cela dans la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##¬†Fusion d'une Conv $3\\times3$ avec une batchnorm puis transfert de poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cr√©ons un mod√®le simple : une couche convolutive suivi d'une couche de batchnormalisation, pour simplifier on ne condi√®re aucune couche d'activation (qui de toute fa√ßon ne rentre pas en jeu). Nous allons :\n",
    "\n",
    "1. Fusionner les deux couches pour cr√©er un nouveau tenseur (poids, biais)\n",
    "2. Transf√©rer ce nouveau tensor dans un mod√®le plus simple `model_after_fusion`.\n",
    "\n",
    "**Remarque** : la convolution dans `model_after_fusion` utilise elle bien un biais (`use_bias = True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38zgF1wjL5Sh",
    "outputId": "a3a18824-f730-4945-947c-714b80134cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        432       \n",
      "_________________________________________________________________\n",
      "bn (BatchNormalization)      (None, 32, 32, 16)        64        \n",
      "=================================================================\n",
      "Total params: 496\n",
      "Trainable params: 464\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=False, kernel_initializer='he_uniform', name='conv')(input)\n",
    "x= BatchNormalization(name='bn')(x)\n",
    "model_before_fusion = Model(input, x)\n",
    "model_before_fusion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        448       \n",
      "=================================================================\n",
      "Total params: 448\n",
      "Trainable params: 448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=True, kernel_initializer='he_normal', name='conv')(input)\n",
    "model_after_fusion = Model(input, x)\n",
    "model_after_fusion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = model_before_fusion.get_layer('conv').get_weights()[0]\n",
    "weights_2 = model_after_fusion.get_layer('conv').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023266133"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(weights_1-weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "eiD6G5F3JQiM"
   },
   "outputs": [],
   "source": [
    "conv = model_before_fusion.get_layer(\"conv\")\n",
    "bn = model_before_fusion.get_layer(\"bn\")\n",
    "  \n",
    "conv_weights, conv_biases = fuse_bn_conv(conv.get_weights(), bn.get_weights())\n",
    "model_after_fusion.get_layer(f\"conv\").set_weights([conv_weights, conv_biases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V√©rifions que la mise en place des nouveaux poids s'est bien pass√©e, ie que l'op√©ration `set_weights()` n'a rien ajout√© de suppl√©mtentaire. Si tout se passe bien, `np.mean` ne devrait renvoyer que des `1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "6sGrv1qXK0Gu"
   },
   "outputs": [],
   "source": [
    "w0, b0 = fuse_bn_conv(model_before_fusion.get_layer(\"conv\").get_weights(), model_before_fusion.get_layer(\"bn\").get_weights())\n",
    "\n",
    "w1, b1 = model_after_fusion.get_layer(\"conv\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "An_AdwOtLtXm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(w0 == w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOcnujGYOvPa",
    "outputId": "93777f28-2bc4-4d11-bde8-73f7e3113a61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(b0 == b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc tout s'est bien pass√©. Reste maintenant √† g√©n√©raliser cette transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'id√©e de RepVGG est d'utiliser une architecture √† la ResNet pour l'entra√Ænement, avec des skips connections, puis lors du d√©ploiement du mod√®le de reparam√©trer les skips connections via des fusions Conv-BN afin de plus avoir qu'une architecture lin√©aire √† la VGG, beaucoup plus rapide en inf√©rence qu'une architecture √† la ResNet.\n",
    "\n",
    "En plus de fusionner des $\\mathrm{Conv} 3 \\times 3$ avec des $\\mathrm{BN}$, il est aussi n√©cessaire de savoir faire les op√©rations suivantes.\n",
    "\n",
    "1. Convertir une $\\mathrm{Conv} 1 \\times 1$ en $\\mathrm{Conv} 3 \\times 3$ puis la fusionner avec la $\\mathrm{BN}$ correspondante.\n",
    "2. Convertir une $\\mathrm{id}$ en $\\mathrm{Conv} 3 \\times 3$ puis la fusionner avec la $\\mathrm{BN}$ correspondante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion d'une Conv $1 \\times 1$ en $3 \\times 3$ puis fusion avec la batchnorm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour convertir une conv 1x1 en conv 3x3 les nombres de canaux en entr√©e et en sortie importe peu, ce qu'il faut c'est modifier la dimension des noyaux de convolutions pour passer d'une dimension 1x1 √† 3x3, et pour cela on utilise un padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        48        \n",
      "_________________________________________________________________\n",
      "bn (BatchNormalization)      (None, 32, 32, 16)        64        \n",
      "=================================================================\n",
      "Total params: 112\n",
      "Trainable params: 80\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=1, padding='same', use_bias=False, kernel_initializer='he_uniform', name='conv')(input)\n",
    "x= BatchNormalization(name='bn')(x)\n",
    "model_before_fusion_conv1 = Model(input, x)\n",
    "model_before_fusion_conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 32, 32, 16)        448       \n",
      "=================================================================\n",
      "Total params: 448\n",
      "Trainable params: 448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(img_shape)\n",
    "x= Conv2D(filters = 16, kernel_size=3, padding='same', use_bias=True, kernel_initializer='he_normal', name='conv')(input)\n",
    "model_after_fusion_conv1 = Model(input, x)\n",
    "model_after_fusion_conv1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_conv1 = model_before_fusion_conv1.get_layer('conv')\n",
    "weights_bn1 = model_before_fusion_conv1.get_layer('bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3, 16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv1.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La premi√®re chose √† faire, c'est de transformer les noyaux de convolution $1\\times1$ en des noyaux de convolution $3\\times3$. Pour faire cela, on utilise la notion de \"padding\", d√©j√† utilis√©e dans le cas des convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.227452]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_conv1.get_weights()[0][:,:,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a deux fonctions possibles pour faire √ßa. On peut utiliser soit la fonction de tensorflow.\n",
    "\n",
    "```python\n",
    "padded_conv1 = tf.pad(weights_conv1.get_weights()[0], [[1,1], [1, 1], [0,0], [0,0]], \"CONSTANT\")\n",
    "```\n",
    "\n",
    "Soit la fonction de numpy.\n",
    "\n",
    "```python\n",
    "padded_conv1 = np.pad(weights_conv1.get_weights()[0], pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)\n",
    "```\n",
    "\n",
    "Dans les deux cas, on a un param√®tre donnant la taille du padding : `[[1,1], [1, 1], [0,0], [0,0]]`, c'est une liste de longueur le nombre d'axes du tenseur que l'on souhaite modifier, chaque √©l√©ment de la liste nous dit de combien on doit agrandir au d√©but et √† la fin.\n",
    "\n",
    "`[[1,1], [1, 1], [0,0], [0,0]] = [[pad_avant_axe1, pad_arri√®re_axe1], [pad_avant_axe2, pad_arri√®re_axe2], [pad_avant_axe3, pad_arri√®re_axe3], [pad_avant_axe4, pad_arri√®re_axe4]]`\n",
    "\n",
    "Le dernier param√®tre nous dit quoi rajouter aux endroits o√π l'on a agrandi, ici des constantes : la valeur $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "YPdg0ab5ajO5"
   },
   "outputs": [],
   "source": [
    "padded_conv1_tf = tf.pad(weights_conv1.get_weights()[0], [[1,1], [1, 1], [0,0], [0,0]], \"CONSTANT\")\n",
    "padded_conv1_np = np.pad(weights_conv1.get_weights()[0], pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux fonctions donnent le m√™me r√©sultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(padded_conv1_tf.numpy()==padded_conv1_np)==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la fonction `set_weights()` demande d'utiliser des `np.array`, on va utiliser la fonction de numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def pad_size_one_kernel(conv_weights):    \n",
    "    return np.pad(conv_weights[0], pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 16)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_weights_conv1 = pad_size_one_kernel(weights_conv1.get_weights())\n",
    "padded_weights_conv1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V√©rification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a transform√© tous les noyaux de convolutions $1\\times1$ en noyaux $3\\times3$, chacun des `padded_weights_conv1[:,:,i,j]` pour $0 \\leq i \\leq 2$ et $0 \\leq j \\leq 15$ doit √™tre une matrice $3\\times3$ o√π tous les √©l√©ments sont nuls sauf possiblement celui du milieu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def test_padded_kernel_conv(padded_kernel):\n",
    "    for i in range(3):\n",
    "        for j in range(16):\n",
    "            print(f'Matrix of size 3x3 : {padded_kernel[:,:,i,j].shape == (3,3)}')\n",
    "            squared_sum = 0\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    if k != 1 and l != 1:\n",
    "                        squared_sum += padded_kernel[:,:,i,j][k,l]**2\n",
    "            print(f'Squared sum is : {squared_sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n"
     ]
    }
   ],
   "source": [
    "test_padded_kernel_conv(padded_weights_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_conv = np.ones(1*1*3*16).reshape((1,1,3,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Squared sum is : 0.0\n"
     ]
    }
   ],
   "source": [
    "padded_dummy_conv=pad_size_one_kernel([dummy_conv])\n",
    "test_padded_kernel_conv(padded_dummy_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pr√©c√©demment, on v√©rifie via les d√©veloppements limit√©s que √ßa fonctionne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv, bn = fuse_bn_conv([padded_dummy_conv], batchnorm_variables(1,2,1,4,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999375"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = compute_scaling_weight_factor(1,4)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.isclose(conv, scale*padded_dummy_conv, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5000625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_scale = compute_scaling_bias_factor(1,2,1,4)\n",
    "bias_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_real = bias_scale*np.ones(16)\n",
    "np.mean(np.isclose(bn_real, bn, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "0pa3HAuZadQt"
   },
   "outputs": [],
   "source": [
    "weights_conv1 = model_before_fusion_conv1.get_layer('conv')\n",
    "weights_bn1 = model_before_fusion_conv1.get_layer('bn')\n",
    "\n",
    "padded_weights_conv1 = pad_size_one_kernel(weights_conv1.get_weights())\n",
    "conv_weights, conv_bias = fuse_bn_conv([padded_weights_conv1], weights_bn1.get_weights())\n",
    "\n",
    "model_after_fusion_conv1.get_layer(\"conv\").set_weights([conv_weights, conv_bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion d'une $\\mathrm{id}$ en $\\mathrm{Conv} 3 \\times 3$ puis fusion avec la batchnorm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les branches id ne sont utilis√©es dans l'architecture de RepVGG que lorsque la conditions `channels_in` = `channels_out` est v√©rifi√©e, c'est √† dire √† l'int√©rieur de chaque stage entre 2 blocs convolutifs avec un stride de 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixons le nombre de channels, peut importe le nombre.\n",
    "channels = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An identity mapping can be viewed as a $1\\times1$ conv with an identity matrix as the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "zal7-PzPg74V",
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def size_three_kernel_from_id(channels):\n",
    "    kernel = np.ones(channels)\n",
    "    kernel = np.diag(kernel)\n",
    "    kernel = np.reshape(kernel, (1,1,channels,channels))\n",
    "    kernel = np.pad(kernel, pad_width=[[1,1], [1, 1], [0,0], [0,0]], mode='constant', constant_values=0)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAlAll12kVRj",
    "outputId": "ccc7720b-af6a-43be-b095-2880d161a0df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 4, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_from_id = size_three_kernel_from_id(4)\n",
    "conv_from_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def test_padded_kernel_from_id(padded_kernel):\n",
    "    for i in range(3):\n",
    "        for j in range(16):\n",
    "            print(f'Matrix of size 3x3 : {padded_kernel[:,:,i,j].shape == (3,3)}')\n",
    "            squared_sum = 0\n",
    "            for k in range(3):\n",
    "                for l in range(3):\n",
    "                    if (k,l) != (1,1):\n",
    "                        squared_sum += padded_kernel[:,:,i,j][k,l]**2\n",
    "                    else:\n",
    "                        print(f'Middle element is 1 : {padded_kernel[:,:,i,j][k,l]==1}')\n",
    "            print(f'Squared sum is : {squared_sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n",
      "Matrix of size 3x3 : True\n",
      "Middle element is 1 : False\n",
      "Squared sum is : 0.0\n"
     ]
    }
   ],
   "source": [
    "test_padded_kernel_from_id(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv, bn = fuse_bn_conv([conv_from_id], batchnorm_variables(1,2,1,4,channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999375"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = compute_scaling_weight_factor(1,4)\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.isclose(conv, scale*conv_from_id, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5000625"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_scale = compute_scaling_bias_factor(1,2,1,4)\n",
    "bias_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_real = bias_scale*np.ones(channels)\n",
    "np.mean(np.isclose(bn_real, bn, rtol=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V√©rification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8AiIqCHo5hH"
   },
   "source": [
    "## Test grandeur r√©elle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def repvgg_block(tensor, filters, num_layer):\n",
    "    \n",
    "    # main stream\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(3,3),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f'block_{num_layer}_conv_main'\n",
    "    )(tensor)\n",
    "    x = BatchNormalization(name=f'block_{num_layer}_bn_main')(x)\n",
    "    \n",
    "    # conv1x1 stream\n",
    "    \n",
    "    y = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(1,1),\n",
    "        strides=(2,2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f'block_{num_layer}_conv_alt'\n",
    "    )(tensor)\n",
    "    y = BatchNormalization(name=f'block_{num_layer}_bn_alt')(y)\n",
    "    \n",
    "    z = Add()([x,y])\n",
    "    \n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def repvgg_block_with_id(tensor, filters, num_layer):\n",
    "\n",
    "    # main stream\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f\"block_{num_layer}_conv_main\",\n",
    "    )(tensor)\n",
    "    x = BatchNormalization(name=f\"block_{num_layer}_bn_main\")(x)\n",
    "\n",
    "    # conv1x1 stream\n",
    "\n",
    "    y = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=(1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        use_bias=False,\n",
    "        name=f\"block_{num_layer}_conv_alt\",\n",
    "    )(tensor)\n",
    "    y = BatchNormalization(name=f\"block_{num_layer}_bn_alt\")(y)\n",
    "\n",
    "    # id_conv branch\n",
    "    z = BatchNormalization(name=f\"block_{num_layer}_bn_id\")(tensor)\n",
    "\n",
    "    return Add()([x, y, z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def get_model(img_shape):\n",
    "\n",
    "    input = Input(img_shape)\n",
    "    \n",
    "    x = repvgg_block(input, filters=64, num_layer=0)\n",
    "    x = ReLU()(x)\n",
    "    x = repvgg_block(x, filters=64, num_layer=1)\n",
    "    x = ReLU()(x)\n",
    "    x = repvgg_block_with_id(x, filters=64, num_layer=2)\n",
    "    x = ReLU()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, name='dense')(x)\n",
    "    x = Softmax()(x)\n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "def get_inference_model(img_shape):\n",
    "    input = Input(img_shape)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), padding='same', name='conv_0')(input)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), padding='same', name='conv_1')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', name='conv_2')(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(10, name='dense')(x)\n",
    "    x = Softmax()(x)\n",
    "    model = Model(input, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block_0_conv_main (Conv2D)      (None, 16, 16, 64)   1728        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_0_conv_alt (Conv2D)       (None, 16, 16, 64)   192         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_0_bn_main (BatchNormaliza (None, 16, 16, 64)   256         block_0_conv_main[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_0_bn_alt (BatchNormalizat (None, 16, 16, 64)   256         block_0_conv_alt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 64)   0           block_0_bn_main[0][0]            \n",
      "                                                                 block_0_bn_alt[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 16, 16, 64)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_main (Conv2D)      (None, 8, 8, 64)     36864       re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_conv_alt (Conv2D)       (None, 8, 8, 64)     4096        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_bn_main (BatchNormaliza (None, 8, 8, 64)     256         block_1_conv_main[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_bn_alt (BatchNormalizat (None, 8, 8, 64)     256         block_1_conv_alt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 64)     0           block_1_bn_main[0][0]            \n",
      "                                                                 block_1_bn_alt[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 8, 8, 64)     0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_main (Conv2D)      (None, 8, 8, 64)     36864       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_2_conv_alt (Conv2D)       (None, 8, 8, 64)     4096        re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_2_bn_main (BatchNormaliza (None, 8, 8, 64)     256         block_2_conv_main[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_bn_alt (BatchNormalizat (None, 8, 8, 64)     256         block_2_conv_alt[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_2_bn_id (BatchNormalizati (None, 8, 8, 64)     256         re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 64)     0           block_2_bn_main[0][0]            \n",
      "                                                                 block_2_bn_alt[0][0]             \n",
      "                                                                 block_2_bn_id[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 8, 8, 64)     0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 4096)         0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           40970       flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_6 (Softmax)             (None, 10)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 126,602\n",
      "Trainable params: 125,706\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model = get_model([32,32,3])\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 16, 16, 64)        1792      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 116,618\n",
      "Trainable params: 116,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_model = get_inference_model([32,32,3])\n",
    "inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": [
     "function"
    ]
   },
   "outputs": [],
   "source": [
    "def from_repvgg_to_vgg(training_model, inference_model, depth):\n",
    "    model = training_model\n",
    "    inference_model = inference_model\n",
    "    \n",
    "    for i in range(depth):\n",
    "        print(f\"Fusion Conv-BN from main branch at depth {i}\")\n",
    "        conv_main = model.get_layer(f\"block_{i}_conv_main\")\n",
    "        bn_main = model.get_layer(f\"block_{i}_bn_main\")\n",
    "\n",
    "        conv_weights_main, conv_biases_main = fuse_bn_conv(\n",
    "            conv_main.get_weights(), bn_main.get_weights()\n",
    "        )\n",
    "\n",
    "        print(f\"Fusion Conv-BN from alt branch at depth {i}\")\n",
    "        conv_alt_one_by_one = model.get_layer(f\"block_{i}_conv_alt\")\n",
    "        bn_alt = model.get_layer(f\"block_{i}_bn_alt\")\n",
    "\n",
    "        conv_alt = pad_size_one_kernel(conv_alt_one_by_one.get_weights())\n",
    "\n",
    "        conv_weights_alt, conv_biases_alt = fuse_bn_conv([conv_alt], bn_alt.get_weights())\n",
    "        \n",
    "        if i==3:\n",
    "            print(f\"Fusion Conv-BN from id branch at depth {i}\")\n",
    "            bn_id = model.get_layer(f\"block_{i}_bn_id\")\n",
    "            channels = backend.int_shape(bn_id.get_weights()[0])[-1]\n",
    "\n",
    "            conv_id = size_three_kernel_from_id(channels)\n",
    "            conv_weights_id, conv_biases_id = fuse_bn_conv([conv_id], bn_id.get_weights())\n",
    "\n",
    "            conv_weights = conv_weights_main + conv_weights_alt + conv_weights_id\n",
    "            conv_biases = conv_biases_main + conv_biases_alt + conv_biases_id\n",
    "        else:\n",
    "            conv_weights = conv_weights_main + conv_weights_alt\n",
    "            conv_biases = conv_biases_main + conv_biases_alt\n",
    "            \n",
    "           \n",
    "        print(f\"Setting weights on inference model at depth {i}\")\n",
    "        inference_model.get_layer(f\"conv_{i}\").set_weights([conv_weights, conv_biases])\n",
    "\n",
    "    dense_weights = model.get_layer(f\"dense\").get_weights()\n",
    "    inference_model.get_layer(f\"dense\").set_weights(dense_weights)\n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train,y_train), (X_test,y_test)  = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "X_train = X_train.reshape(-1, 32, 32, 3).astype('float32')\n",
    "X_test = X_test.reshape(-1, 32, 32, 3).astype('float32')\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, random_state=42)\n",
    "\n",
    "y_train_oh = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_oh = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "y_valid_oh = tf.keras.utils.to_categorical(y_valid, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 2s 4ms/step - loss: 1.9390 - accuracy: 0.3690 - val_loss: 1.4326 - val_accuracy: 0.4882\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 1.1761 - accuracy: 0.5805 - val_loss: 1.2776 - val_accuracy: 0.5559\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.9771 - accuracy: 0.6608 - val_loss: 1.2784 - val_accuracy: 0.5692\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.8457 - accuracy: 0.7047 - val_loss: 1.1538 - val_accuracy: 0.6070\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.7411 - accuracy: 0.7415 - val_loss: 1.1523 - val_accuracy: 0.6082\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.6627 - accuracy: 0.7721 - val_loss: 1.2050 - val_accuracy: 0.6056\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.5730 - accuracy: 0.8017 - val_loss: 1.3360 - val_accuracy: 0.5908\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.5037 - accuracy: 0.8267 - val_loss: 1.2697 - val_accuracy: 0.6086\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.8549 - val_loss: 1.6375 - val_accuracy: 0.5710\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.8732 - val_loss: 1.4501 - val_accuracy: 0.6078\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.8947 - val_loss: 1.3964 - val_accuracy: 0.6189\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.2657 - accuracy: 0.9140 - val_loss: 1.4346 - val_accuracy: 0.6252\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.2328 - accuracy: 0.9247 - val_loss: 1.7435 - val_accuracy: 0.6030\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9402 - val_loss: 1.6220 - val_accuracy: 0.6197\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1661 - accuracy: 0.9486 - val_loss: 2.0838 - val_accuracy: 0.5826\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9539 - val_loss: 1.6913 - val_accuracy: 0.6221\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1283 - accuracy: 0.9603 - val_loss: 1.7873 - val_accuracy: 0.6273\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 1.9872 - val_accuracy: 0.6094\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9691 - val_loss: 2.0423 - val_accuracy: 0.6062\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9666 - val_loss: 2.0206 - val_accuracy: 0.6166\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0920 - accuracy: 0.9714 - val_loss: 2.0964 - val_accuracy: 0.6199\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9750 - val_loss: 2.4125 - val_accuracy: 0.5951\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0647 - accuracy: 0.9814 - val_loss: 2.2896 - val_accuracy: 0.6095\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0907 - accuracy: 0.9686 - val_loss: 2.3337 - val_accuracy: 0.6104\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9755 - val_loss: 2.7223 - val_accuracy: 0.5977\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9804 - val_loss: 2.3225 - val_accuracy: 0.6226\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0616 - accuracy: 0.9815 - val_loss: 2.3531 - val_accuracy: 0.6187\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9862 - val_loss: 2.5024 - val_accuracy: 0.6199\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 2.9272 - val_accuracy: 0.5823\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9745 - val_loss: 2.4670 - val_accuracy: 0.6142\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0780 - accuracy: 0.9733 - val_loss: 2.6590 - val_accuracy: 0.6194\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9776 - val_loss: 2.5846 - val_accuracy: 0.6173\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9898 - val_loss: 2.5448 - val_accuracy: 0.6227\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 2.6284 - val_accuracy: 0.6238\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 2.8331 - val_accuracy: 0.6170\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9809 - val_loss: 3.3461 - val_accuracy: 0.5866\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0740 - accuracy: 0.9740 - val_loss: 2.9504 - val_accuracy: 0.6025\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9749 - val_loss: 2.7457 - val_accuracy: 0.6227\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9849 - val_loss: 2.7979 - val_accuracy: 0.6226\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9929 - val_loss: 2.8238 - val_accuracy: 0.6207\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 2.8020 - val_accuracy: 0.6298\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 2.8443 - val_accuracy: 0.6261\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9870 - val_loss: 4.3773 - val_accuracy: 0.5440\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9646 - val_loss: 3.0375 - val_accuracy: 0.6030\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9799 - val_loss: 2.8326 - val_accuracy: 0.6314\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 2.8987 - val_accuracy: 0.6274\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 2.9066 - val_accuracy: 0.6258\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 3.0005 - val_accuracy: 0.6267\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 2.9672 - val_accuracy: 0.6337\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 3.4715 - val_accuracy: 0.5854\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9634 - val_loss: 3.1194 - val_accuracy: 0.6069\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 3.4825 - val_accuracy: 0.6022\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 3.1542 - val_accuracy: 0.6277\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 3.0385 - val_accuracy: 0.6305\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 3.0361 - val_accuracy: 0.6351\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 3.0368 - val_accuracy: 0.6361\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 3.1196 - val_accuracy: 0.6257\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 3.2946 - val_accuracy: 0.6184\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0844 - accuracy: 0.9726 - val_loss: 3.6981 - val_accuracy: 0.5838\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9615 - val_loss: 3.3662 - val_accuracy: 0.6150\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 3.1085 - val_accuracy: 0.6268\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 3.2636 - val_accuracy: 0.6290\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 3.1850 - val_accuracy: 0.6310\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 3.2820 - val_accuracy: 0.6345\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 3.1574 - val_accuracy: 0.6397\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1854 - val_accuracy: 0.6414\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1196 - val_accuracy: 0.6458\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.6865e-04 - accuracy: 1.0000 - val_loss: 3.1958 - val_accuracy: 0.6469\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.6404e-04 - accuracy: 1.0000 - val_loss: 3.1414 - val_accuracy: 0.6472\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.8577e-04 - accuracy: 1.0000 - val_loss: 3.1648 - val_accuracy: 0.6446\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.2701e-04 - accuracy: 1.0000 - val_loss: 3.2118 - val_accuracy: 0.6478\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1478 - accuracy: 0.9627 - val_loss: 3.3232 - val_accuracy: 0.5995\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1219 - accuracy: 0.9585 - val_loss: 3.0879 - val_accuracy: 0.6179\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 3.1610 - val_accuracy: 0.6290\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 3.0288 - val_accuracy: 0.6348\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 3.0254 - val_accuracy: 0.6465\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 3.0743 - val_accuracy: 0.6470\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 3.1198 - val_accuracy: 0.6430\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0889 - val_accuracy: 0.6466\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.1780 - val_accuracy: 0.6393\n",
      "Epoch 81/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1530 - val_accuracy: 0.6427\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.9041e-04 - accuracy: 1.0000 - val_loss: 3.1667 - val_accuracy: 0.6454\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.6558e-04 - accuracy: 1.0000 - val_loss: 3.1835 - val_accuracy: 0.6430\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9710 - val_loss: 4.0625 - val_accuracy: 0.5772\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1073 - accuracy: 0.9622 - val_loss: 3.1034 - val_accuracy: 0.6308\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 3.1997 - val_accuracy: 0.6258\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 3.2102 - val_accuracy: 0.6319\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 3.1613 - val_accuracy: 0.6379\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 3.2062 - val_accuracy: 0.6387\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 3.1607 - val_accuracy: 0.6414\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.1905 - val_accuracy: 0.6446\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 3.2038 - val_accuracy: 0.6442\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 3.2732 - val_accuracy: 0.6409\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 7.5633e-04 - accuracy: 1.0000 - val_loss: 3.2499 - val_accuracy: 0.6442\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 7.7323e-04 - accuracy: 1.0000 - val_loss: 3.2885 - val_accuracy: 0.6450\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.9023e-04 - accuracy: 1.0000 - val_loss: 3.4087 - val_accuracy: 0.6306\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 5.3897 - val_accuracy: 0.5452\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.9175 - val_loss: 3.8454 - val_accuracy: 0.5955\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9852 - val_loss: 3.4719 - val_accuracy: 0.6225\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 3.4143 - val_accuracy: 0.6262\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 3.2489 - val_accuracy: 0.6374\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 3.2455 - val_accuracy: 0.6399\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2159 - val_accuracy: 0.6434\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2219 - val_accuracy: 0.6451\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2600 - val_accuracy: 0.6425\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.9068e-04 - accuracy: 1.0000 - val_loss: 3.2839 - val_accuracy: 0.6430\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 8.8232e-04 - accuracy: 1.0000 - val_loss: 3.2854 - val_accuracy: 0.6457\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3356e-04 - accuracy: 1.0000 - val_loss: 3.3021 - val_accuracy: 0.6451\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.9747e-04 - accuracy: 1.0000 - val_loss: 3.3147 - val_accuracy: 0.6457\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.3339e-04 - accuracy: 1.0000 - val_loss: 3.3380 - val_accuracy: 0.6454\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 4.3812e-04 - accuracy: 1.0000 - val_loss: 3.3765 - val_accuracy: 0.6447\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.1380e-04 - accuracy: 1.0000 - val_loss: 3.3854 - val_accuracy: 0.6460\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.5256e-04 - accuracy: 1.0000 - val_loss: 3.4450 - val_accuracy: 0.6454\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9867 - val_loss: 3.9023 - val_accuracy: 0.5873\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9468 - val_loss: 3.3988 - val_accuracy: 0.6180\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 3.3156 - val_accuracy: 0.6344\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 3.2564 - val_accuracy: 0.6354\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 3.3034 - val_accuracy: 0.6414\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 3.3015 - val_accuracy: 0.6431\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 3.3338 - val_accuracy: 0.6422\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3000 - val_accuracy: 0.6458\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 9.2647e-04 - accuracy: 1.0000 - val_loss: 3.3178 - val_accuracy: 0.6457\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 8.6534e-04 - accuracy: 1.0000 - val_loss: 3.3308 - val_accuracy: 0.6482\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3539e-04 - accuracy: 1.0000 - val_loss: 3.3759 - val_accuracy: 0.6479\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.1540e-04 - accuracy: 1.0000 - val_loss: 3.3861 - val_accuracy: 0.6474\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.1956e-04 - accuracy: 1.0000 - val_loss: 3.3955 - val_accuracy: 0.6460\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.9951e-04 - accuracy: 1.0000 - val_loss: 3.5187 - val_accuracy: 0.6467\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 4.4000 - val_accuracy: 0.5709\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.2555 - accuracy: 0.9294 - val_loss: 3.7346 - val_accuracy: 0.6086\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 3.4413 - val_accuracy: 0.6241\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 3.4731 - val_accuracy: 0.6366\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 3.3815 - val_accuracy: 0.6391\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 3.4015 - val_accuracy: 0.6413\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 3.4036 - val_accuracy: 0.6428\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.4494 - val_accuracy: 0.6402\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 3.4177 - val_accuracy: 0.6470\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.6482e-04 - accuracy: 1.0000 - val_loss: 3.4614 - val_accuracy: 0.6452\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.2557e-04 - accuracy: 1.0000 - val_loss: 3.4649 - val_accuracy: 0.6465\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.4032e-04 - accuracy: 1.0000 - val_loss: 3.4694 - val_accuracy: 0.6444\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.6854e-04 - accuracy: 1.0000 - val_loss: 3.5629 - val_accuracy: 0.6450\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.7389e-04 - accuracy: 1.0000 - val_loss: 3.5976 - val_accuracy: 0.6391\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.9803 - val_loss: 3.6825 - val_accuracy: 0.6078\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9660 - val_loss: 3.4045 - val_accuracy: 0.6313\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 3.5080 - val_accuracy: 0.6366\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 3.4096 - val_accuracy: 0.6414\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 3.4737 - val_accuracy: 0.6436\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 3.5510 - val_accuracy: 0.6415\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 3.5113 - val_accuracy: 0.6454\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4949 - val_accuracy: 0.6440\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 3.5232 - val_accuracy: 0.6479\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.0308e-04 - accuracy: 1.0000 - val_loss: 3.5569 - val_accuracy: 0.6500\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.7638e-04 - accuracy: 1.0000 - val_loss: 3.5668 - val_accuracy: 0.6485\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3473e-04 - accuracy: 1.0000 - val_loss: 3.5986 - val_accuracy: 0.6502\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.5041e-04 - accuracy: 1.0000 - val_loss: 3.5845 - val_accuracy: 0.6482\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 4.0400e-04 - accuracy: 1.0000 - val_loss: 3.6154 - val_accuracy: 0.6446\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.3062e-04 - accuracy: 1.0000 - val_loss: 3.7590 - val_accuracy: 0.6394\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9545 - val_loss: 3.6780 - val_accuracy: 0.6218\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 3.5992 - val_accuracy: 0.6316\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 3.7416 - val_accuracy: 0.6269\n",
      "Epoch 160/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 3.5675 - val_accuracy: 0.6382\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 3.6239 - val_accuracy: 0.6394\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 3.5901 - val_accuracy: 0.6389\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 3.6193 - val_accuracy: 0.6441\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 3.6285 - val_accuracy: 0.6438\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 7.3676e-04 - accuracy: 1.0000 - val_loss: 3.6237 - val_accuracy: 0.6454\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.4252e-04 - accuracy: 1.0000 - val_loss: 3.6783 - val_accuracy: 0.6441\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.7206e-04 - accuracy: 1.0000 - val_loss: 3.6587 - val_accuracy: 0.6457\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.1652e-04 - accuracy: 1.0000 - val_loss: 3.6578 - val_accuracy: 0.6467\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 4.2009 - val_accuracy: 0.5858\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9697 - val_loss: 3.5935 - val_accuracy: 0.6283\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 3.6487 - val_accuracy: 0.6332\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 3.8405 - val_accuracy: 0.6329\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 3.6509 - val_accuracy: 0.6421\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 3.6520 - val_accuracy: 0.6394\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.6577 - val_accuracy: 0.6406\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 6.8113e-04 - accuracy: 1.0000 - val_loss: 3.6778 - val_accuracy: 0.6417\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 8.0387e-04 - accuracy: 1.0000 - val_loss: 3.6704 - val_accuracy: 0.6414\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 6.4948e-04 - accuracy: 1.0000 - val_loss: 3.7070 - val_accuracy: 0.6417\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 4.2156e-04 - accuracy: 1.0000 - val_loss: 3.7131 - val_accuracy: 0.6404\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.7091e-04 - accuracy: 1.0000 - val_loss: 3.8784 - val_accuracy: 0.6346\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0651 - accuracy: 0.9804 - val_loss: 4.3902 - val_accuracy: 0.5985\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0633 - accuracy: 0.9788 - val_loss: 4.0795 - val_accuracy: 0.6162\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 4.0404 - val_accuracy: 0.6267\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 3.7312 - val_accuracy: 0.6357\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 3.7239 - val_accuracy: 0.6436\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 3.7600 - val_accuracy: 0.6344\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 3.7408 - val_accuracy: 0.6391\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 3.8037 - val_accuracy: 0.6379\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 3.8553 - val_accuracy: 0.6378\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 4.3736 - val_accuracy: 0.6046\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 0.0759 - accuracy: 0.9757 - val_loss: 4.1114 - val_accuracy: 0.6099\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9879 - val_loss: 4.0255 - val_accuracy: 0.6281\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 3.9506 - val_accuracy: 0.6345\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 3.9339 - val_accuracy: 0.6302\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 3.8998 - val_accuracy: 0.6373\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 3.8751 - val_accuracy: 0.6438\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 9.7056e-04 - accuracy: 1.0000 - val_loss: 3.8705 - val_accuracy: 0.6424\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.4642e-04 - accuracy: 1.0000 - val_loss: 3.8781 - val_accuracy: 0.6441\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 5.2847e-04 - accuracy: 1.0000 - val_loss: 3.8988 - val_accuracy: 0.6422\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 5.0220e-04 - accuracy: 1.0000 - val_loss: 3.9146 - val_accuracy: 0.6449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc892648ca0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "training_model.fit(X_train, y_train_oh,\n",
    "                     epochs = 200,\n",
    "                     batch_size=128,\n",
    "                     validation_data=(X_valid, y_valid_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 4.0375 - accuracy: 0.6408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.037524223327637, 0.6407999992370605]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model.evaluate(X_test, y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Conv-BN from main branch at depth 0\n",
      "Fusion Conv-BN from alt branch at depth 0\n",
      "Setting weights on inference model at depth 0\n",
      "Fusion Conv-BN from main branch at depth 1\n",
      "Fusion Conv-BN from alt branch at depth 1\n",
      "Setting weights on inference model at depth 1\n",
      "Fusion Conv-BN from main branch at depth 2\n",
      "Fusion Conv-BN from alt branch at depth 2\n",
      "Setting weights on inference model at depth 2\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 16, 16, 64)        1792      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 116,618\n",
      "Trainable params: 116,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = from_repvgg_to_vgg(training_model, inference_model, 3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.SGD(lr=2e-9),\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 7.8139 - accuracy: 0.3986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.867744445800781, 0.39640000462532043]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "fusion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
